{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fcafb0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import findspark\n",
    "#findspark.init()\n",
    "#import pyspark # only run after findspark.init()\n",
    "#from pyspark.sql import SparkSession\n",
    "#spark = SparkSession.builder.getOrCreate()\n",
    "import pandas as pd\n",
    "#sc = spark.sparkContext\n",
    "import json \n",
    "from sodapy import Socrata\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import numpy as np \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "17b36604",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cb024005",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"data.buffalony.gov\"\n",
    "db=\"d6g9-xbgu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5d5fdf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('data/wrangled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c32ee9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 273439 entries, 0 to 273438\n",
      "Data columns (total 10 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   Unnamed: 0            273439 non-null  int64  \n",
      " 1   incident_datetime     273439 non-null  object \n",
      " 2   address_1             273439 non-null  object \n",
      " 3   city                  273439 non-null  object \n",
      " 4   state                 273439 non-null  object \n",
      " 5   latitude              273439 non-null  float64\n",
      " 6   longitude             273439 non-null  float64\n",
      " 7   hour_of_day           273439 non-null  int64  \n",
      " 8   day_of_week           273439 non-null  object \n",
      " 9   parent_incident_type  273439 non-null  object \n",
      "dtypes: float64(2), int64(2), object(6)\n",
      "memory usage: 20.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "536685e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning1(df):\n",
    "    df=df[['incident_datetime', 'latitude', 'longitude', 'day_of_week','parent_incident_type']]\n",
    "    df.incident_datetime=pd.to_datetime(df.incident_datetime)\n",
    "    df.latitude=df.latitude.astype(float)\n",
    "    df.longitude=df.longitude.astype(float)\n",
    "    df.day_of_week=df.day_of_week.str.replace('SATURDAY','Saturday')\n",
    "    df.day_of_week=df.day_of_week.str.replace('FRIDAY','Friday')\n",
    "    df.day_of_week=df.day_of_week.str.replace('SUNDAY', 'Sunday')\n",
    "    df.day_of_week=df.day_of_week.str.replace('MONDAY','Monday')\n",
    "    df.day_of_week=df.day_of_week.str.replace('TUESDAY','Tuesday')\n",
    "    df.day_of_week=df.day_of_week.str.replace('WEDNESDAY','Wednesday')\n",
    "    df.day_of_week=df.day_of_week.str.replace('THURSDAY','Thursday')\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "46ca6f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned1=data_cleaning1(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9f3b647c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['incident_datetime', 'latitude', 'longitude', 'day_of_week',\n",
       "       'parent_incident_type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef482485",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cde5fa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned=cleaned1\n",
    "cleaned=cleaned.sort_values('incident_datetime')\n",
    "cleaned=cleaned.set_index('incident_datetime')\n",
    "cleaned=cleaned.loc[\"01-01-2010\":]\n",
    "cleaned.head()\n",
    "cleaned=cleaned.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "59916122",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned['log']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c2959d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 196062 entries, 0 to 196061\n",
      "Data columns (total 6 columns):\n",
      " #   Column                Non-Null Count   Dtype         \n",
      "---  ------                --------------   -----         \n",
      " 0   incident_datetime     196062 non-null  datetime64[ns]\n",
      " 1   latitude              196062 non-null  float64       \n",
      " 2   longitude             196062 non-null  float64       \n",
      " 3   day_of_week           196062 non-null  object        \n",
      " 4   parent_incident_type  196062 non-null  object        \n",
      " 5   log                   196062 non-null  int64         \n",
      "dtypes: datetime64[ns](1), float64(2), int64(1), object(2)\n",
      "memory usage: 9.0+ MB\n"
     ]
    }
   ],
   "source": [
    "cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "32f8f0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test=sliced_advanced(cleaned,'01-01-2021','01-02-2021')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "402c31cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>parent_incident_type</th>\n",
       "      <th>log</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incident_datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-01 00:00:00</th>\n",
       "      <td>42.874699</td>\n",
       "      <td>-78.823627</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Theft</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-01 00:00:00</th>\n",
       "      <td>42.927216</td>\n",
       "      <td>-78.848810</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Other Sexual Offense</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-01 00:00:00</th>\n",
       "      <td>42.941782</td>\n",
       "      <td>-78.883643</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Theft of Vehicle</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-01 00:00:00</th>\n",
       "      <td>42.935244</td>\n",
       "      <td>-78.829687</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Other Sexual Offense</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-01 00:00:00</th>\n",
       "      <td>42.839594</td>\n",
       "      <td>-78.801492</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Theft</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-01 21:46:30</th>\n",
       "      <td>42.937000</td>\n",
       "      <td>-78.851000</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Theft of Vehicle</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-01 22:00:00</th>\n",
       "      <td>42.919000</td>\n",
       "      <td>-78.856000</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>Theft of Vehicle</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-01 22:00:00</th>\n",
       "      <td>42.883000</td>\n",
       "      <td>-78.866000</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>Assault</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-01 22:10:00</th>\n",
       "      <td>42.899000</td>\n",
       "      <td>-78.835000</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Robbery</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-01 23:42:39</th>\n",
       "      <td>42.873000</td>\n",
       "      <td>-78.825000</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Assault</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>188860 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      latitude  longitude day_of_week  parent_incident_type  \\\n",
       "incident_datetime                                                             \n",
       "2010-01-01 00:00:00  42.874699 -78.823627      Friday                 Theft   \n",
       "2010-01-01 00:00:00  42.927216 -78.848810      Friday  Other Sexual Offense   \n",
       "2010-01-01 00:00:00  42.941782 -78.883643      Friday      Theft of Vehicle   \n",
       "2010-01-01 00:00:00  42.935244 -78.829687      Friday  Other Sexual Offense   \n",
       "2010-01-01 00:00:00  42.839594 -78.801492      Friday                 Theft   \n",
       "...                        ...        ...         ...                   ...   \n",
       "2021-01-01 21:46:30  42.937000 -78.851000      Friday      Theft of Vehicle   \n",
       "2021-01-01 22:00:00  42.919000 -78.856000    Saturday      Theft of Vehicle   \n",
       "2021-01-01 22:00:00  42.883000 -78.866000      Sunday               Assault   \n",
       "2021-01-01 22:10:00  42.899000 -78.835000      Friday               Robbery   \n",
       "2021-01-01 23:42:39  42.873000 -78.825000      Friday               Assault   \n",
       "\n",
       "                     log  \n",
       "incident_datetime         \n",
       "2010-01-01 00:00:00    1  \n",
       "2010-01-01 00:00:00    1  \n",
       "2010-01-01 00:00:00    1  \n",
       "2010-01-01 00:00:00    1  \n",
       "2010-01-01 00:00:00    1  \n",
       "...                  ...  \n",
       "2021-01-01 21:46:30    1  \n",
       "2021-01-01 22:00:00    1  \n",
       "2021-01-01 22:00:00    1  \n",
       "2021-01-01 22:10:00    1  \n",
       "2021-01-01 23:42:39    1  \n",
       "\n",
       "[188860 rows x 5 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "264cd879",
   "metadata": {},
   "outputs": [],
   "source": [
    "date=cleaned[['incident_datetime','log']]\n",
    "date=date.set_index('incident_datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8f0070bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_resampled=date.resample('5 min').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ce825981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incident_datetime</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-01 00:00:00</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-01 00:05:00</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-01 00:10:00</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-01 00:15:00</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-01 00:20:00</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-31 02:15:00</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-31 02:20:00</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-31 02:25:00</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-31 02:30:00</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-31 02:35:00</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1226912 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     log\n",
       "incident_datetime       \n",
       "2010-01-01 00:00:00   24\n",
       "2010-01-01 00:05:00    1\n",
       "2010-01-01 00:10:00    1\n",
       "2010-01-01 00:15:00    0\n",
       "2010-01-01 00:20:00    0\n",
       "...                  ...\n",
       "2021-08-31 02:15:00    0\n",
       "2021-08-31 02:20:00    0\n",
       "2021-08-31 02:25:00    0\n",
       "2021-08-31 02:30:00    0\n",
       "2021-08-31 02:35:00    1\n",
       "\n",
       "[1226912 rows x 1 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8d4049ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='incident_datetime'>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "date_resampled.plot(kind='line')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b47e22",
   "metadata": {},
   "source": [
    " # dataframe ready for modeling , functions were made to promptly import all types of data , cleaned and ready to go. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "51661fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a test split function\n",
    "def train_test(df,train_end_date,test_start_date):\n",
    "    train=df.loc[:train_end_date]\n",
    "    test=df.loc[test_start_date:]\n",
    "    return train,test\n",
    "date_train,date_test=train_test(date_resampled,'01-01-2021','01-02-2021')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d534201",
   "metadata": {},
   "source": [
    "# Time series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dc85edba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 1157472 entries, 2010-01-01 00:00:00 to 2021-01-01 23:55:00\n",
      "Freq: 5T\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count    Dtype\n",
      "---  ------  --------------    -----\n",
      " 0   log     1157472 non-null  int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 17.7 MB\n"
     ]
    }
   ],
   "source": [
    "date_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c3ee2eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incident_datetime</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-02 00:10:00</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-02 00:10:00</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-02 01:00:00</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-02 01:29:26</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-02 05:44:30</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-30 19:10:35</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-30 19:30:00</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-30 21:15:00</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-30 23:18:04</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-31 02:35:24</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7202 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     log\n",
       "incident_datetime       \n",
       "2021-01-02 00:10:00    1\n",
       "2021-01-02 00:10:00    1\n",
       "2021-01-02 01:00:00    1\n",
       "2021-01-02 01:29:26    1\n",
       "2021-01-02 05:44:30    1\n",
       "...                  ...\n",
       "2021-08-30 19:10:35    1\n",
       "2021-08-30 19:30:00    1\n",
       "2021-08-30 21:15:00    1\n",
       "2021-08-30 23:18:04    1\n",
       "2021-08-31 02:35:24    1\n",
       "\n",
       "[7202 rows x 1 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8e73c0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_train,date_test=train_test(date,'01-01-2021','01-02-2021')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fbac136a",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_train=date_train.reset_index()\n",
    "X=date_train.incident_datetime\n",
    "Y=date_train.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "b1fbc505",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima_model import ARMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.arima_process import ArmaProcess\n",
    "from statsmodels.graphics.tsaplots import plot_pacf,plot_acf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee292b2",
   "metadata": {},
   "source": [
    "date data is ready for predictive modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7fc23ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_acf(date_train.resample('1h').sum(),lags=62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "399b5764",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=date_train.resample('15 min').sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "eb7eb8bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(385823, 1)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "36d6b6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmioi\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:581: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  warnings.warn('A date index has been provided, but it has no'\n",
      "C:\\Users\\mmioi\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:581: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  warnings.warn('A date index has been provided, but it has no'\n"
     ]
    }
   ],
   "source": [
    "model=SARIMAX(date_train,order=(0,1,0),seasonal_order=(0,0,0,24))\n",
    "res1=model.fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "71b805cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=res1.predict(start='12-25-2020',end='01-01-2021')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "fa4b5a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "incident_datetime\n",
       "2020-12-25 00:00:00    5.0\n",
       "2020-12-25 01:00:00    0.0\n",
       "2020-12-25 02:00:00    2.0\n",
       "2020-12-25 03:00:00    0.0\n",
       "2020-12-25 04:00:00    0.0\n",
       "                      ... \n",
       "2020-12-31 20:00:00    4.0\n",
       "2020-12-31 21:00:00    2.0\n",
       "2020-12-31 22:00:00    2.0\n",
       "2020-12-31 23:00:00    3.0\n",
       "2021-01-01 00:00:00    1.0\n",
       "Freq: H, Name: predicted_mean, Length: 169, dtype: float64"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.resample('1h').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d778b9b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test=date_train.loc['12-25-2020':]\n",
    "predsdf=pd.DataFrame(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2099d835",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-94-85a52a944192>:3: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  ax22=fig.add_subplot(111)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x127941301f0>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax1=fig.add_subplot(111)\n",
    "ax22=fig.add_subplot(111)\n",
    "\n",
    "ax1.plot(predsdf.resample('1m').sum(),color='blue',label='Pred')\n",
    "ax1.set_title('preds vs True')\n",
    "ax22.plot(date_train.resample('1m').sum(),color='red',label='True ')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d2f4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "exog=date_test.reset_index().incident_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f28d58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b60c6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "exog.set_index(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f321b369",
   "metadata": {},
   "source": [
    "# classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df145a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies=pd.get_dummies(cleaned.day_of_week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "ab192b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed=pd.merge(cleaned,dummies,left_index=True,right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "3a7cf3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed=pre_processed.drop('day_of_week',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "25b085ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed=pre_processed.set_index('incident_datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "7950a570",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X=pre_processed.drop('parent_incident_type',axis=1)\n",
    "Y=pre_processed.parent_incident_type.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "ecb2bef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.20,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "48a788e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as rf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d47431ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  200\n",
      "Accuracy score (training): 0.445\n",
      "Accuracy score (validation): 0.443\n",
      "\n",
      "Learning rate:  400\n",
      "Accuracy score (training): 0.445\n",
      "Accuracy score (validation): 0.443\n",
      "\n",
      "Learning rate:  600\n",
      "Accuracy score (training): 0.445\n",
      "Accuracy score (validation): 0.443\n",
      "\n",
      "Learning rate:  1000\n",
      "Accuracy score (training): 0.445\n",
      "Accuracy score (validation): 0.443\n",
      "\n",
      "Learning rate:  2000\n",
      "Accuracy score (training): 0.445\n",
      "Accuracy score (validation): 0.443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_e = [200,400, 600, 1000, 2000]\n",
    "\n",
    "for n in n_e:\n",
    "    from sklearn.ensemble import RandomForestClassifier as rf\n",
    "    rf = rf(n_estimators=n, max_depth = 5, random_state = 0,n_features=20,bootstrap=False,criterion='entropy')\n",
    "    rf.fit(X_train, y_train)\n",
    "    print(\"Learning rate: \", n)\n",
    "    print(\"Accuracy score (training): {0:.3f}\".format(rf.score(X_train, y_train)))\n",
    "    print(\"Accuracy score (validation): {0:.3f}\".format(rf.score(X_test, y_test)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "6a0f99bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "43f8569f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.05\n",
      "Accuracy score (training): 0.447\n",
      "Accuracy score (validation): 0.445\n",
      "\n",
      "Learning rate:  0.1\n",
      "Accuracy score (training): 0.448\n",
      "Accuracy score (validation): 0.446\n",
      "\n",
      "Learning rate:  0.25\n",
      "Accuracy score (training): 0.450\n",
      "Accuracy score (validation): 0.447\n",
      "\n",
      "Learning rate:  0.5\n",
      "Accuracy score (training): 0.193\n",
      "Accuracy score (validation): 0.195\n",
      "\n",
      "Learning rate:  0.75\n",
      "Accuracy score (training): 0.135\n",
      "Accuracy score (validation): 0.134\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-139-2fec9088f324>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlearning_rates\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mgb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Learning rate: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy score (training): {0:.3f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m         \u001b[1;31m# fit the boosting stages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 504\u001b[1;33m         n_stages = self._fit_stages(\n\u001b[0m\u001b[0;32m    505\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rng\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m             sample_weight_val, begin_at_stage, monitor)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m             \u001b[1;31m# fit next stage of trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m             raw_predictions = self._fit_stage(\n\u001b[0m\u001b[0;32m    562\u001b[0m                 \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m                 random_state, X_csc, X_csr)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m             tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[0m\u001b[0;32m    215\u001b[0m                      check_input=False)\n\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1245\u001b[0m         \"\"\"\n\u001b[0;32m   1246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1247\u001b[1;33m         super().fit(\n\u001b[0m\u001b[0;32m   1248\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1249\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    387\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    388\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learning_rates = [0.05, 0.1, 0.25, 0.5, 0.75, 1]\n",
    "for learning_rate in learning_rates:\n",
    "    gb = GradientBoostingClassifier(n_estimators=200, learning_rate = learning_rate, max_features=5, max_depth = 2, random_state = 0)\n",
    "    gb.fit(X_train, y_train)\n",
    "    print(\"Learning rate: \", learning_rate)\n",
    "    print(\"Accuracy score (training): {0:.3f}\".format(gb.score(X_train, y_train)))\n",
    "    print(\"Accuracy score (validation): {0:.3f}\".format(gb.score(X_test, y_test)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff84894",
   "metadata": {},
   "source": [
    "both gb and fr failed spectacularly. reducing the amount of categories \n",
    "/ three different catregories [Sexual , Violent,Property]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "b2f341e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Theft', 'Other Sexual Offense', 'Breaking & Entering',\n",
       "       'Sexual Assault', 'Theft of Vehicle', 'Assault', 'Robbery',\n",
       "       'Homicide', 'Sexual Offense'], dtype=object)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_processed.parent_incident_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "de7581f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed.parent_incident_type=pre_processed.parent_incident_type.str.replace('Breaking & Entering','Property')\n",
    "pre_processed.parent_incident_type=pre_processed.parent_incident_type.str.replace('Theft of Vehicle','Property')\n",
    "pre_processed.parent_incident_type=pre_processed.parent_incident_type.str.replace('Theft','Property')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "82f0e3e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Property', 'Other Sexual Offense', 'Sexual Assault', 'Assault',\n",
       "       'Robbery', 'Homicide', 'Sexual Offense'], dtype=object)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_processed.parent_incident_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "a8c47e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed.parent_incident_type=pre_processed.parent_incident_type.str.replace('Robbery','Violent')\n",
    "pre_processed.parent_incident_type=pre_processed.parent_incident_type.str.replace( 'Assault','Violent')\n",
    "pre_processed.parent_incident_type=pre_processed.parent_incident_type.str.replace('Homicide','Violent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "cab17f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed.parent_incident_type=pre_processed.parent_incident_type.str.replace('Sexual Assault','Sexual')\n",
    "pre_processed.parent_incident_type=pre_processed.parent_incident_type.str.replace('Sexual Offense','Sexual')\n",
    "pre_processed.parent_incident_type=pre_processed.parent_incident_type.str.replace('Other Sexual Offense','Sexual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "ec494f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Property', 'Other Sexual', 'Sexual', 'Violent'], dtype=object)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_processed.parent_incident_type.unique()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "593cbc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed.parent_incident_type=pre_processed.parent_incident_type.str.replace('Other Sexual','Sexual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "f6af37ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Property', 'Sexual', 'Violent'], dtype=object)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_processed.parent_incident_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "3f80a681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  20\n",
      "Accuracy score (training): 0.706\n",
      "Accuracy score (validation): 0.706\n",
      "\n",
      "Learning rate:  40\n",
      "Accuracy score (training): 0.706\n",
      "Accuracy score (validation): 0.706\n",
      "\n",
      "Learning rate:  60\n",
      "Accuracy score (training): 0.706\n",
      "Accuracy score (validation): 0.706\n",
      "\n",
      "Learning rate:  100\n",
      "Accuracy score (training): 0.706\n",
      "Accuracy score (validation): 0.706\n",
      "\n",
      "Learning rate:  200\n",
      "Accuracy score (training): 0.706\n",
      "Accuracy score (validation): 0.706\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_e = [20,40, 60, 100, 200]\n",
    "\n",
    "for n in n_e:\n",
    "    from sklearn.ensemble import RandomForestClassifier as rf\n",
    "    rf = rf(n_estimators=100, max_depth = 5, random_state = 0,bootstrap=False,criterion='entropy')\n",
    "    rf.fit(X_train, y_train)\n",
    "    print(\"Learning rate: \", n)\n",
    "    print(\"Accuracy score (training): {0:.3f}\".format(rf.score(X_train, y_train)))\n",
    "    print(\"Accuracy score (validation): {0:.3f}\".format(rf.score(X_test, y_test)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "f0d1aa7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.05\n",
      "Accuracy score (training): 0.707\n",
      "Accuracy score (validation): 0.707\n",
      "\n",
      "Learning rate:  0.1\n",
      "Accuracy score (training): 0.708\n",
      "Accuracy score (validation): 0.707\n",
      "\n",
      "Learning rate:  0.25\n",
      "Accuracy score (training): 0.711\n",
      "Accuracy score (validation): 0.708\n",
      "\n",
      "Learning rate:  0.5\n",
      "Accuracy score (training): 0.715\n",
      "Accuracy score (validation): 0.708\n",
      "\n",
      "Learning rate:  0.75\n",
      "Accuracy score (training): 0.718\n",
      "Accuracy score (validation): 0.705\n",
      "\n",
      "Learning rate:  1\n",
      "Accuracy score (training): 0.716\n",
      "Accuracy score (validation): 0.704\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [0.05, 0.1, 0.25, 0.5, 0.75, 1]\n",
    "for learning_rate in learning_rates:\n",
    "    gb = GradientBoostingClassifier(n_estimators=100, learning_rate = learning_rate, max_features=5, max_depth = 4, random_state = 0)\n",
    "    gb.fit(X_train, y_train)\n",
    "    print(\"Learning rate: \", learning_rate)\n",
    "    print(\"Accuracy score (training): {0:.3f}\".format(gb.score(X_train, y_train)))\n",
    "    print(\"Accuracy score (validation): {0:.3f}\".format(gb.score(X_test, y_test)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "2b180505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "parent_incident_type\n",
       "Property    0.506343\n",
       "Sexual      0.012602\n",
       "Violent     0.198077\n",
       "dtype: float64"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_probs = pre_processed.dropna().groupby('parent_incident_type').size().div(len(df))\n",
    "rating_probs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "9a07ab81",
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays=pd.read_csv(r'C:\\Users\\mmioi\\Downloads\\US Holiday Dates (2004-2021).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "b5bb0d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Holiday</th>\n",
       "      <th>WeekDay</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004-07-04</td>\n",
       "      <td>4th of July</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2005-07-04</td>\n",
       "      <td>4th of July</td>\n",
       "      <td>Monday</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-07-04</td>\n",
       "      <td>4th of July</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-07-04</td>\n",
       "      <td>4th of July</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-07-04</td>\n",
       "      <td>4th of July</td>\n",
       "      <td>Friday</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Holiday    WeekDay  Month  Day  Year\n",
       "0  2004-07-04  4th of July     Sunday      7    4  2004\n",
       "1  2005-07-04  4th of July     Monday      7    4  2005\n",
       "2  2006-07-04  4th of July    Tuesday      7    4  2006\n",
       "3  2007-07-04  4th of July  Wednesday      7    4  2007\n",
       "4  2008-07-04  4th of July     Friday      7    4  2008"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holidays.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "ac4a6412",
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays=holidays[['Date','Holiday']]\n",
    "holidays.Date=pd.to_datetime(holidays.Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "804fba9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 342 entries, 2004-07-04 to 2011-04-24\n",
      "Data columns (total 1 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   Holiday  342 non-null    object\n",
      "dtypes: object(1)\n",
      "memory usage: 5.3+ KB\n"
     ]
    }
   ],
   "source": [
    "holidays=holidays.set_index('Date')\n",
    "holidays.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "2ae0d8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays=pd.get_dummies(holidays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "67a38cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays=holidays.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "fe0bb346",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed1=pre_processed.join(holidays,how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "47e5aa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed1=pre_processed1.replace(np.nan,0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "cf5984de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 196080 entries, 2010-01-01 00:00:00 to 2021-08-31 02:35:24\n",
      "Data columns (total 29 columns):\n",
      " #   Column                               Non-Null Count   Dtype  \n",
      "---  ------                               --------------   -----  \n",
      " 0   latitude                             196080 non-null  float64\n",
      " 1   longitude                            196080 non-null  float64\n",
      " 2   parent_incident_type                 196080 non-null  object \n",
      " 3   log                                  196080 non-null  int64  \n",
      " 4   Friday                               196080 non-null  uint8  \n",
      " 5   Monday                               196080 non-null  uint8  \n",
      " 6   Saturday                             196080 non-null  uint8  \n",
      " 7   Sunday                               196080 non-null  uint8  \n",
      " 8   Thursday                             196080 non-null  uint8  \n",
      " 9   Tuesday                              196080 non-null  uint8  \n",
      " 10  Wednesday                            196080 non-null  uint8  \n",
      " 11  Holiday_4th of July                  196080 non-null  float64\n",
      " 12  Holiday_Christmas Day                196080 non-null  float64\n",
      " 13  Holiday_Christmas Eve                196080 non-null  float64\n",
      " 14  Holiday_Columbus Day                 196080 non-null  float64\n",
      " 15  Holiday_Eastern Easter               196080 non-null  float64\n",
      " 16  Holiday_Juneteenth                   196080 non-null  float64\n",
      " 17  Holiday_Labor Day                    196080 non-null  float64\n",
      " 18  Holiday_Labor Day Weekend            196080 non-null  float64\n",
      " 19  Holiday_Martin Luther King, Jr. Day  196080 non-null  float64\n",
      " 20  Holiday_Memorial Day                 196080 non-null  float64\n",
      " 21  Holiday_New Year's Day               196080 non-null  float64\n",
      " 22  Holiday_New Year’s Eve               196080 non-null  float64\n",
      " 23  Holiday_Thanksgiving Day             196080 non-null  float64\n",
      " 24  Holiday_Thanksgiving Eve             196080 non-null  float64\n",
      " 25  Holiday_Valentine’s Day              196080 non-null  float64\n",
      " 26  Holiday_Veterans Day                 196080 non-null  float64\n",
      " 27  Holiday_Washington's Birthday        196080 non-null  float64\n",
      " 28  Holiday_Western Easter               196080 non-null  float64\n",
      "dtypes: float64(20), int64(1), object(1), uint8(7)\n",
      "memory usage: 35.7+ MB\n"
     ]
    }
   ],
   "source": [
    "pre_processed1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "eee67ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=pre_processed1.drop('parent_incident_type',axis=1)\n",
    "Y=pre_processed1.parent_incident_type.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "dccc2fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.20,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "d002f5c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  2\n",
      "Accuracy score (training): 0.705\n",
      "Accuracy score (validation): 0.709\n",
      "\n",
      "Learning rate:  3\n",
      "Accuracy score (training): 0.705\n",
      "Accuracy score (validation): 0.709\n",
      "\n",
      "Learning rate:  4\n",
      "Accuracy score (training): 0.705\n",
      "Accuracy score (validation): 0.709\n",
      "\n",
      "Learning rate:  5\n",
      "Accuracy score (training): 0.705\n",
      "Accuracy score (validation): 0.709\n",
      "\n",
      "Learning rate:  7\n",
      "Accuracy score (training): 0.705\n",
      "Accuracy score (validation): 0.709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "md = [2,3,4,5,7,]\n",
    "\n",
    "for n in md:\n",
    "    from sklearn.ensemble import RandomForestClassifier as rf\n",
    "    rf = rf(n_estimators=200, max_depth = 2,max_leaf_nodes=n, random_state = 123,bootstrap=True,criterion='gini')\n",
    "    rf.fit(X_train, y_train)\n",
    "    print(\"Learning rate: \", n)\n",
    "    print(\"Accuracy score (training): {0:.3f}\".format(rf.score(X_train, y_train)))\n",
    "    print(\"Accuracy score (validation): {0:.3f}\".format(rf.score(X_test, y_test)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "efa59025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.01\n",
      "Accuracy score (training): 0.705\n",
      "Accuracy score (validation): 0.709\n",
      "\n",
      "Learning rate:  0.02\n",
      "Accuracy score (training): 0.705\n",
      "Accuracy score (validation): 0.709\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-300-fe140829c594>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlearning_rates\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mgb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Learning rate: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy score (training): {0:.3f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    503\u001b[0m         \u001b[1;31m# fit the boosting stages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 504\u001b[1;33m         n_stages = self._fit_stages(\n\u001b[0m\u001b[0;32m    505\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rng\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m             sample_weight_val, begin_at_stage, monitor)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[1;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m             \u001b[1;31m# fit next stage of trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m             raw_predictions = self._fit_stage(\n\u001b[0m\u001b[0;32m    562\u001b[0m                 \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m                 random_state, X_csc, X_csr)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[1;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m             tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[0m\u001b[0;32m    215\u001b[0m                      check_input=False)\n\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1245\u001b[0m         \"\"\"\n\u001b[0;32m   1246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1247\u001b[1;33m         super().fit(\n\u001b[0m\u001b[0;32m   1248\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1249\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    387\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    388\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learning_rates = [0.01,0.02,0.05, 0.1, 0.25, 0.5, 0.75, 1]\n",
    "for learning_rate in learning_rates:\n",
    "    gb = GradientBoostingClassifier(n_estimators=500, learning_rate = learning_rate, max_features=4, max_depth = 3, random_state = 0)\n",
    "    gb.fit(X_train, y_train)\n",
    "    print(\"Learning rate: \", learning_rate)\n",
    "    print(\"Accuracy score (training): {0:.3f}\".format(gb.score(X_train, y_train)))\n",
    "    print(\"Accuracy score (validation): {0:.3f}\".format(gb.score(X_test, y_test)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "a63b8d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  7\n",
      "Accuracy score (training): 0.705\n",
      "Accuracy score (validation): 0.709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as rf\n",
    "rf = rf(n_estimators=200, max_depth = 2,random_state = 123,bootstrap=True,criterion='gini')\n",
    "rf.fit(X_train, y_train)\n",
    "print(\"Learning rate: \", n)\n",
    "print(\"Accuracy score (training): {0:.3f}\".format(rf.score(X_train, y_train)))\n",
    "print(\"Accuracy score (validation): {0:.3f}\".format(rf.score(X_test, y_test)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "9effb4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred=rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "ad9c5889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27820,     0,     0],\n",
       "       [  689,     0,     0],\n",
       "       [10707,     0,     0]], dtype=int64)"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "5bb03f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmioi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Property       0.71      1.00      0.83     27820\n",
      "      Sexual       0.00      0.00      0.00       689\n",
      "     Violent       0.00      0.00      0.00     10707\n",
      "\n",
      "    accuracy                           0.71     39216\n",
      "   macro avg       0.24      0.33      0.28     39216\n",
      "weighted avg       0.50      0.71      0.59     39216\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmioi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\mmioi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,ypred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "34a0cbde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['latitude', 'longitude', 'parent_incident_type', 'log', 'Friday',\n",
       "       'Monday', 'Saturday', 'Sunday', 'Thursday', 'Tuesday', 'Wednesday',\n",
       "       'Holiday_4th of July', 'Holiday_Christmas Day', 'Holiday_Christmas Eve',\n",
       "       'Holiday_Columbus Day', 'Holiday_Eastern Easter', 'Holiday_Juneteenth',\n",
       "       'Holiday_Labor Day', 'Holiday_Labor Day Weekend',\n",
       "       'Holiday_Martin Luther King, Jr. Day', 'Holiday_Memorial Day',\n",
       "       'Holiday_New Year's Day', 'Holiday_New Year’s Eve',\n",
       "       'Holiday_Thanksgiving Day', 'Holiday_Thanksgiving Eve',\n",
       "       'Holiday_Valentine’s Day', 'Holiday_Veterans Day',\n",
       "       'Holiday_Washington's Birthday', 'Holiday_Western Easter'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_processed1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "65826cbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Property    138467\n",
       "Violent      54166\n",
       "Sexual        3447\n",
       "Name: parent_incident_type, dtype: int64"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_processed1.parent_incident_type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd22b27",
   "metadata": {},
   "source": [
    "# Balancing the DataSet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "cfa37514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class count\n",
    "count_class_0, count_class_1 ,count_class_2= pre_processed1.parent_incident_type.value_counts()\n",
    "\n",
    "# Divide by class\n",
    "df_class_0 = pre_processed1[pre_processed1['parent_incident_type'] == 'Property']\n",
    "df_class_1 = pre_processed1[pre_processed1['parent_incident_type'] == 'Violent']\n",
    "df_class_2 = pre_processed1[pre_processed1['parent_incident_type'] == 'Sexual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "433e8715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random under-sampling:\n",
      "Violent     54166\n",
      "Property    54166\n",
      "Sexual       3447\n",
      "Name: parent_incident_type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Undersample 0-class and concat the DataFrames of both class\n",
    "df_class_0_under = df_class_0.sample(count_class_1)\n",
    "df_test_under = pd.concat([df_class_0_under, df_class_1,df_class_2], axis=0)\n",
    "\n",
    "print('Random under-sampling:')\n",
    "print(df_test_under.parent_incident_type.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "6602a9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_test_under.drop('parent_incident_type',axis=1)\n",
    "Y=df_test_under.parent_incident_type.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "73717f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "ac459c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  2\n",
      "Accuracy score (training): 0.545\n",
      "Accuracy score (validation): 0.542\n",
      "\n",
      "Learning rate:  3\n",
      "Accuracy score (training): 0.545\n",
      "Accuracy score (validation): 0.543\n",
      "\n",
      "Learning rate:  4\n",
      "Accuracy score (training): 0.547\n",
      "Accuracy score (validation): 0.545\n",
      "\n",
      "Learning rate:  5\n",
      "Accuracy score (training): 0.547\n",
      "Accuracy score (validation): 0.545\n",
      "\n",
      "Learning rate:  7\n",
      "Accuracy score (training): 0.547\n",
      "Accuracy score (validation): 0.545\n",
      "\n"
     ]
    }
   ],
   "source": [
    "md = [2,3,4,5,7,]\n",
    "\n",
    "for n in md:\n",
    "    from sklearn.ensemble import RandomForestClassifier as rf\n",
    "    rf = rf(n_estimators=200, max_depth = 2,max_leaf_nodes=n, random_state = 123,bootstrap=True,criterion='gini')\n",
    "    rf.fit(X_train, y_train)\n",
    "    print(\"Learning rate: \", n)\n",
    "    print(\"Accuracy score (training): {0:.3f}\".format(rf.score(X_train, y_train)))\n",
    "    print(\"Accuracy score (validation): {0:.3f}\".format(rf.score(X_test, y_test)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "c5441892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "abc824a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "93015136",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_under.parent_incident_type=df_test_under.parent_incident_type.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "dac4433a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test1=pd.DataFrame(df_test_under)\n",
    "df_test_under=df_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "7897139d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_under.parent_incident_type=df_test_under.parent_incident_type.replace('Violent',1)\n",
    "df_test_under.parent_incident_type=df_test_under.parent_incident_type.replace('Property',0)\n",
    "df_test_under.parent_incident_type=df_test_under.parent_incident_type.replace('Sexual',2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "f6814aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_under.parent_incident_type.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "65637fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_test_under.drop('parent_incident_type',axis=1).values\n",
    "Y=df_test_under.parent_incident_type.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "ba3c4301",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANN(X_train, y_train, X_test, y_test, loss, weights):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(28, input_dim=28, activation='relu'),\n",
    "        keras.layers.Dense(52, activation='relu'),\n",
    "        keras.layers.Dense(28, activation='relu'),\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n",
    "    \n",
    "    if weights == -1:\n",
    "        model.fit(X_train, y_train, epochs=50)\n",
    "    else:\n",
    "        model.fit(X_train, y_train, epochs=50, class_weight = weights)\n",
    "    \n",
    "    print(model.evaluate(X_test, y_test))\n",
    "    \n",
    "    y_preds = model.predict(X_test)\n",
    "    y_preds = np.round(y_preds)\n",
    "    \n",
    "    print(\"Classification Report: \\n\", classification_report(y_test, y_preds))\n",
    "    \n",
    "    return y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "bfc2ae99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2795/2795 [==============================] - 1s 469us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 2/100\n",
      "2795/2795 [==============================] - 1s 452us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 3/100\n",
      "2795/2795 [==============================] - 1s 453us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 4/100\n",
      "2795/2795 [==============================] - 1s 463us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 5/100\n",
      "2795/2795 [==============================] - 1s 454us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 6/100\n",
      "2795/2795 [==============================] - 1s 456us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 7/100\n",
      "2795/2795 [==============================] - 1s 453us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 8/100\n",
      "2795/2795 [==============================] - 1s 459us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 9/100\n",
      "2795/2795 [==============================] - 1s 454us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 10/100\n",
      "2795/2795 [==============================] - 1s 456us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 11/100\n",
      "2795/2795 [==============================] - 1s 461us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 12/100\n",
      "2795/2795 [==============================] - 1s 456us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 13/100\n",
      "2795/2795 [==============================] - 1s 456us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 14/100\n",
      "2795/2795 [==============================] - 1s 456us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 15/100\n",
      "2795/2795 [==============================] - 1s 461us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 16/100\n",
      "2795/2795 [==============================] - 1s 462us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 17/100\n",
      "2795/2795 [==============================] - 1s 455us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 18/100\n",
      "2795/2795 [==============================] - 1s 463us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 19/100\n",
      "2795/2795 [==============================] - 1s 458us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 20/100\n",
      "2795/2795 [==============================] - 1s 459us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 21/100\n",
      "2795/2795 [==============================] - 1s 454us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 22/100\n",
      "2795/2795 [==============================] - 1s 457us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 23/100\n",
      "2795/2795 [==============================] - 1s 454us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 24/100\n",
      "2795/2795 [==============================] - 1s 455us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 25/100\n",
      "2795/2795 [==============================] - 1s 458us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 26/100\n",
      "2795/2795 [==============================] - 1s 457us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 27/100\n",
      "2795/2795 [==============================] - 1s 458us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 28/100\n",
      "2795/2795 [==============================] - 1s 463us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 29/100\n",
      "2795/2795 [==============================] - 1s 463us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 30/100\n",
      "2795/2795 [==============================] - 1s 455us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 31/100\n",
      "2795/2795 [==============================] - 1s 458us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 32/100\n",
      "2795/2795 [==============================] - 1s 461us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 33/100\n",
      "2795/2795 [==============================] - 1s 456us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 34/100\n",
      "2795/2795 [==============================] - 1s 454us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 35/100\n",
      "2795/2795 [==============================] - 1s 458us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 36/100\n",
      "2795/2795 [==============================] - 1s 461us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 37/100\n",
      "2795/2795 [==============================] - 1s 454us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 38/100\n",
      "2795/2795 [==============================] - 1s 453us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 39/100\n",
      "2795/2795 [==============================] - 1s 456us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 40/100\n",
      "2795/2795 [==============================] - 1s 463us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 41/100\n",
      "2795/2795 [==============================] - 1s 486us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 42/100\n",
      "2795/2795 [==============================] - 1s 479us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 43/100\n",
      "2795/2795 [==============================] - 1s 474us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 44/100\n",
      "2795/2795 [==============================] - 1s 473us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 45/100\n",
      "2795/2795 [==============================] - 1s 485us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 46/100\n",
      "2795/2795 [==============================] - 1s 461us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 47/100\n",
      "2795/2795 [==============================] - 1s 466us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 48/100\n",
      "2795/2795 [==============================] - 1s 469us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 49/100\n",
      "2795/2795 [==============================] - 1s 460us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 50/100\n",
      "2795/2795 [==============================] - 1s 461us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 51/100\n",
      "2795/2795 [==============================] - 1s 459us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 52/100\n",
      "2795/2795 [==============================] - 1s 467us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 53/100\n",
      "2795/2795 [==============================] - 1s 476us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 54/100\n",
      "2795/2795 [==============================] - 1s 480us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 55/100\n",
      "2795/2795 [==============================] - 1s 473us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 56/100\n",
      "2795/2795 [==============================] - 1s 471us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 57/100\n",
      "2795/2795 [==============================] - 1s 471us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 58/100\n",
      "2795/2795 [==============================] - 1s 465us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 59/100\n",
      "2795/2795 [==============================] - 1s 475us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 60/100\n",
      "2795/2795 [==============================] - 1s 459us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 61/100\n",
      "2795/2795 [==============================] - 1s 461us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 62/100\n",
      "2795/2795 [==============================] - 1s 459us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 63/100\n",
      "2795/2795 [==============================] - 1s 469us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 64/100\n",
      "2795/2795 [==============================] - 1s 461us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 65/100\n",
      "2795/2795 [==============================] - 1s 468us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 66/100\n",
      "2795/2795 [==============================] - 1s 473us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 67/100\n",
      "2795/2795 [==============================] - 1s 471us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 68/100\n",
      "2795/2795 [==============================] - 1s 469us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 69/100\n",
      "2795/2795 [==============================] - 1s 469us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 70/100\n",
      "2795/2795 [==============================] - 1s 467us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 71/100\n",
      "2795/2795 [==============================] - 1s 465us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 72/100\n",
      "2795/2795 [==============================] - 1s 465us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 73/100\n",
      "2795/2795 [==============================] - 1s 466us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 74/100\n",
      "2795/2795 [==============================] - 1s 466us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2795/2795 [==============================] - 1s 457us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 76/100\n",
      "2795/2795 [==============================] - 1s 463us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 77/100\n",
      "2795/2795 [==============================] - 1s 460us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 78/100\n",
      "2795/2795 [==============================] - 1s 475us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 79/100\n",
      "2795/2795 [==============================] - 1s 461us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 80/100\n",
      "2795/2795 [==============================] - 1s 467us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 81/100\n",
      "2795/2795 [==============================] - 1s 463us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 82/100\n",
      "2795/2795 [==============================] - 1s 471us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 83/100\n",
      "2795/2795 [==============================] - 1s 464us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 84/100\n",
      "2795/2795 [==============================] - 1s 463us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 85/100\n",
      "2795/2795 [==============================] - 1s 461us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 86/100\n",
      "2795/2795 [==============================] - 1s 459us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 87/100\n",
      "2795/2795 [==============================] - 1s 461us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 88/100\n",
      "2795/2795 [==============================] - 1s 467us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 89/100\n",
      "2795/2795 [==============================] - 1s 469us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 90/100\n",
      "2795/2795 [==============================] - 1s 478us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 91/100\n",
      "2795/2795 [==============================] - 1s 460us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 92/100\n",
      "2795/2795 [==============================] - 1s 467us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 93/100\n",
      "2795/2795 [==============================] - 1s 460us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 94/100\n",
      "2795/2795 [==============================] - 1s 460us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 95/100\n",
      "2795/2795 [==============================] - 1s 458us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 96/100\n",
      "2795/2795 [==============================] - 1s 460us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 97/100\n",
      "2795/2795 [==============================] - 1s 461us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 98/100\n",
      "2795/2795 [==============================] - 1s 459us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 99/100\n",
      "2795/2795 [==============================] - 1s 456us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "Epoch 100/100\n",
      "2795/2795 [==============================] - 1s 461us/step - loss: 6.5068e-08 - accuracy: 0.4848\n",
      "699/699 [==============================] - 0s 325us/step - loss: 6.5321e-08 - accuracy: 0.4839\n",
      "[6.532089003030705e-08, 0.48385220766067505]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      1.00      0.65     10817\n",
      "           1       0.00      0.00      0.00     10828\n",
      "           2       0.00      0.00      0.00       711\n",
      "\n",
      "    accuracy                           0.48     22356\n",
      "   macro avg       0.16      0.33      0.22     22356\n",
      "weighted avg       0.23      0.48      0.32     22356\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmioi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\mmioi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\mmioi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANN(X_train, y_train, X_test, y_test,\"categorical_crossentropy\", -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "2617432b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_processed2=pre_processed1\n",
    "pre_processed2.parent_incident_type=pre_processed2.parent_incident_type.replace('Violent',1)\n",
    "pre_processed2.parent_incident_type=pre_processed2.parent_incident_type.replace('Property',0)\n",
    "pre_processed2.parent_incident_type=pre_processed2.parent_incident_type.replace('Sexual',2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "b5559b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=pre_processed2.drop('parent_incident_type',axis=1).values\n",
    "Y=pre_processed2.parent_incident_type.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "e2b745d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "4902/4902 [==============================] - 2s 457us/step - loss: 1.0002 - accuracy: 0.7072\n",
      "Epoch 2/50\n",
      "4902/4902 [==============================] - 2s 447us/step - loss: 1.0000 - accuracy: 0.7072\n",
      "Epoch 3/50\n",
      "4902/4902 [==============================] - 2s 450us/step - loss: 1.0000 - accuracy: 0.7072\n",
      "Epoch 4/50\n",
      "4902/4902 [==============================] - 2s 451us/step - loss: 1.0000 - accuracy: 0.7072\n",
      "Epoch 5/50\n",
      "4902/4902 [==============================] - 2s 447us/step - loss: 1.0000 - accuracy: 0.7072\n",
      "Epoch 6/50\n",
      "4902/4902 [==============================] - 2s 449us/step - loss: 1.0000 - accuracy: 0.7072\n",
      "Epoch 7/50\n",
      "4902/4902 [==============================] - 2s 449us/step - loss: 1.0000 - accuracy: 0.7072\n",
      "Epoch 8/50\n",
      "4902/4902 [==============================] - 2s 463us/step - loss: 1.0000 - accuracy: 0.7072\n",
      "Epoch 9/50\n",
      "4902/4902 [==============================] - 2s 473us/step - loss: 1.0000 - accuracy: 0.7072\n",
      "Epoch 10/50\n",
      "4902/4902 [==============================] - 2s 462us/step - loss: 1.0000 - accuracy: 0.7072\n",
      "Epoch 11/50\n",
      "4902/4902 [==============================] - 2s 462us/step - loss: 1.0000 - accuracy: 0.7072\n",
      "Epoch 12/50\n",
      "4902/4902 [==============================] - 2s 446us/step - loss: 1.0000 - accuracy: 0.7072\n",
      "Epoch 13/50\n",
      "4902/4902 [==============================] - 2s 454us/step - loss: 1.0000 - accuracy: 0.7072\n",
      "Epoch 14/50\n",
      "4902/4902 [==============================] - 2s 451us/step - loss: 1.0000 - accuracy: 0.7072\n",
      "Epoch 15/50\n",
      "4902/4902 [==============================] - 2s 472us/step - loss: 1.0000 - accuracy: 0.7072\n",
      "Epoch 16/50\n",
      "4902/4902 [==============================] - 2s 461us/step - loss: 1.0000 - accuracy: 0.7072\n",
      "Epoch 17/50\n",
      "4902/4902 [==============================] - 2s 477us/step - loss: 1.0000 - accuracy: 0.7072\n",
      "Epoch 18/50\n",
      "4902/4902 [==============================] - 2s 464us/step - loss: 1.0000 - accuracy: 0.7072\n",
      "Epoch 19/50\n",
      "4902/4902 [==============================] - 2s 488us/step - loss: 1.0000 - accuracy: 0.7072\n",
      "Epoch 20/50\n",
      "4902/4902 [==============================] - 2s 479us/step - loss: 1.0000 - accuracy: 0.7072\n",
      "Epoch 21/50\n",
      "4902/4902 [==============================] - 2s 479us/step - loss: 1.0000 - accuracy: 0.7072\n",
      "Epoch 22/50\n",
      "4902/4902 [==============================] - 2s 467us/step - loss: 1.0000 - accuracy: 0.7072\n",
      "Epoch 23/50\n",
      "4902/4902 [==============================] - 2s 460us/step - loss: 1.0000 - accuracy: 0.7072\n",
      "Epoch 24/50\n",
      "4902/4902 [==============================] - 2s 482us/step - loss: 1.0000 - accuracy: 0.7072\n",
      "Epoch 25/50\n",
      "4902/4902 [==============================] - 2s 487us/step - loss: 1.0000 - accuracy: 0.7072\n",
      "Epoch 26/50\n",
      "4902/4902 [==============================] - 2s 461us/step - loss: 1.0000 - accuracy: 0.7072\n",
      "Epoch 27/50\n",
      "4902/4902 [==============================] - 2s 464us/step - loss: 1.0000 - accuracy: 0.7072\n",
      "Epoch 28/50\n",
      "4902/4902 [==============================] - 2s 463us/step - loss: 1.0000 - accuracy: 0.7072\n",
      "Epoch 29/50\n",
      "4902/4902 [==============================] - 2s 459us/step - loss: 1.0000 - accuracy: 0.7072\n",
      "Epoch 30/50\n",
      "4902/4902 [==============================] - 2s 461us/step - loss: 1.0000 - accuracy: 0.7072\n",
      "Epoch 31/50\n",
      "4902/4902 [==============================] - 2s 464us/step - loss: 1.0000 - accuracy: 0.7072\n",
      "Epoch 32/50\n",
      "4902/4902 [==============================] - 2s 463us/step - loss: 1.0000 - accuracy: 0.7072\n",
      "Epoch 33/50\n",
      "4902/4902 [==============================] - 2s 462us/step - loss: 1.0000 - accuracy: 0.7072\n",
      "Epoch 34/50\n",
      "4902/4902 [==============================] - 2s 459us/step - loss: 1.0000 - accuracy: 0.7072\n",
      "Epoch 35/50\n",
      "4902/4902 [==============================] - 2s 456us/step - loss: 1.0000 - accuracy: 0.7072\n",
      "Epoch 36/50\n",
      "4902/4902 [==============================] - 2s 459us/step - loss: 1.0000 - accuracy: 0.7072\n",
      "Epoch 37/50\n",
      "4902/4902 [==============================] - 2s 458us/step - loss: 1.0000 - accuracy: 0.7072\n",
      "Epoch 38/50\n",
      "4902/4902 [==============================] - 2s 458us/step - loss: 1.0000 - accuracy: 0.7072\n",
      "Epoch 39/50\n",
      "4902/4902 [==============================] - 2s 465us/step - loss: 1.0000 - accuracy: 0.7072\n",
      "Epoch 40/50\n",
      "4902/4902 [==============================] - 2s 454us/step - loss: 1.0000 - accuracy: 0.7072\n",
      "Epoch 41/50\n",
      "4902/4902 [==============================] - 2s 454us/step - loss: 1.0000 - accuracy: 0.7072\n",
      "Epoch 42/50\n",
      "4902/4902 [==============================] - 2s 459us/step - loss: 1.0000 - accuracy: 0.7072\n",
      "Epoch 43/50\n",
      "4902/4902 [==============================] - 2s 474us/step - loss: 1.0000 - accuracy: 0.7072\n",
      "Epoch 44/50\n",
      "4902/4902 [==============================] - 2s 463us/step - loss: 1.0000 - accuracy: 0.7072\n",
      "Epoch 45/50\n",
      "4902/4902 [==============================] - 2s 457us/step - loss: 1.0000 - accuracy: 0.7072\n",
      "Epoch 46/50\n",
      "4902/4902 [==============================] - 2s 455us/step - loss: 1.0000 - accuracy: 0.7072\n",
      "Epoch 47/50\n",
      "4902/4902 [==============================] - 2s 451us/step - loss: 1.0000 - accuracy: 0.7072\n",
      "Epoch 48/50\n",
      "4902/4902 [==============================] - 2s 464us/step - loss: 1.0000 - accuracy: 0.7072\n",
      "Epoch 49/50\n",
      "4902/4902 [==============================] - 2s 454us/step - loss: 1.0000 - accuracy: 0.7072\n",
      "Epoch 50/50\n",
      "4902/4902 [==============================] - 2s 450us/step - loss: 1.0000 - accuracy: 0.7072\n",
      "1226/1226 [==============================] - 0s 335us/step - loss: 1.0000 - accuracy: 0.7019\n",
      "[1.0, 0.7018818855285645]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      1.00      0.82     27525\n",
      "           1       0.00      0.00      0.00     10958\n",
      "           2       0.00      0.00      0.00       733\n",
      "\n",
      "    accuracy                           0.70     39216\n",
      "   macro avg       0.23      0.33      0.27     39216\n",
      "weighted avg       0.49      0.70      0.58     39216\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmioi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\mmioi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\mmioi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANN(X_train, y_train, X_test, y_test,\"squared_hinge\", -2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "f01721f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement urllib\n",
      "ERROR: No matching distribution found for urllib\n"
     ]
    }
   ],
   "source": [
    "pip install urllib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "74e7256a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4\n",
      "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\mmioi\\anaconda3\\lib\\site-packages (from bs4) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\mmioi\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.2.1)\n",
      "Building wheels for collected packages: bs4\n",
      "  Building wheel for bs4 (setup.py): started\n",
      "  Building wheel for bs4 (setup.py): finished with status 'done'\n",
      "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1273 sha256=1c13df6730db89bae9639e6061b6160198defe6296a24a53b4f1820925816707\n",
      "  Stored in directory: c:\\users\\mmioi\\appdata\\local\\pip\\cache\\wheels\\75\\78\\21\\68b124549c9bdc94f822c02fb9aa3578a669843f9767776bca\n",
      "Successfully built bs4\n",
      "Installing collected packages: bs4\n",
      "Successfully installed bs4-0.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install bs4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10e5453",
   "metadata": {},
   "source": [
    "# adding Buffalo's event Calendar as a new feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d96da6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4 \n",
    "from urllib.request import urlopen as ureq\n",
    "from bs4 import BeautifulSoup as soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "47885113",
   "metadata": {},
   "outputs": [],
   "source": [
    "url=r'C:\\Users\\mmioi\\Downloads\\calendar.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "af440cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_soup=soup(url,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7e46b93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_soup.body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "ec9daa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "hello=pd.read_csv(r'C:\\Users\\mmioi\\Downloads\\Calendar cleaned.csv',header=None,index_col=None,parse_dates=True,infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "b07e9786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype='int64')"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hello.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "c8829872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>February</td>\n",
       "      <td>10</td>\n",
       "      <td>2018</td>\n",
       "      <td>10:00</td>\n",
       "      <td>AM</td>\n",
       "      <td>-</td>\n",
       "      <td>12:30</td>\n",
       "      <td>PM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>February</td>\n",
       "      <td>10</td>\n",
       "      <td>2018</td>\n",
       "      <td>10:30</td>\n",
       "      <td>AM</td>\n",
       "      <td>-</td>\n",
       "      <td>12:15</td>\n",
       "      <td>PM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>February</td>\n",
       "      <td>10</td>\n",
       "      <td>2018</td>\n",
       "      <td>12:00</td>\n",
       "      <td>PM</td>\n",
       "      <td>-</td>\n",
       "      <td>4:00</td>\n",
       "      <td>PM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>March</td>\n",
       "      <td>3</td>\n",
       "      <td>2018</td>\n",
       "      <td>12:00</td>\n",
       "      <td>PM</td>\n",
       "      <td>-</td>\n",
       "      <td>3:00</td>\n",
       "      <td>PM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>March</td>\n",
       "      <td>17</td>\n",
       "      <td>2018</td>\n",
       "      <td>12:00</td>\n",
       "      <td>PM</td>\n",
       "      <td>-</td>\n",
       "      <td>2:00</td>\n",
       "      <td>PM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>November</td>\n",
       "      <td>13</td>\n",
       "      <td>2021</td>\n",
       "      <td>8:00</td>\n",
       "      <td>AM</td>\n",
       "      <td>-</td>\n",
       "      <td>1:00</td>\n",
       "      <td>PM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>November</td>\n",
       "      <td>20</td>\n",
       "      <td>2021</td>\n",
       "      <td>8:00</td>\n",
       "      <td>AM</td>\n",
       "      <td>-</td>\n",
       "      <td>1:00</td>\n",
       "      <td>PM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>November</td>\n",
       "      <td>25</td>\n",
       "      <td>2021</td>\n",
       "      <td>9:00</td>\n",
       "      <td>AM</td>\n",
       "      <td>-</td>\n",
       "      <td>12:00</td>\n",
       "      <td>PM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>November</td>\n",
       "      <td>27</td>\n",
       "      <td>2021</td>\n",
       "      <td>8:00</td>\n",
       "      <td>AM</td>\n",
       "      <td>-</td>\n",
       "      <td>1:00</td>\n",
       "      <td>PM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>December</td>\n",
       "      <td>4</td>\n",
       "      <td>2021</td>\n",
       "      <td>11:00</td>\n",
       "      <td>AM</td>\n",
       "      <td>-</td>\n",
       "      <td>8:00</td>\n",
       "      <td>PM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1128 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0   1     2      3   4  5      6   7    8   9\n",
       "0     February  10  2018  10:00  AM  -  12:30  PM  NaN NaN\n",
       "1     February  10  2018  10:30  AM  -  12:15  PM  NaN NaN\n",
       "2     February  10  2018  12:00  PM  -   4:00  PM  NaN NaN\n",
       "3        March   3  2018  12:00  PM  -   3:00  PM  NaN NaN\n",
       "4        March  17  2018  12:00  PM  -   2:00  PM  NaN NaN\n",
       "...        ...  ..   ...    ...  .. ..    ...  ..  ...  ..\n",
       "1123  November  13  2021   8:00  AM  -   1:00  PM  NaN NaN\n",
       "1124  November  20  2021   8:00  AM  -   1:00  PM  NaN NaN\n",
       "1125  November  25  2021   9:00  AM  -  12:00  PM  NaN NaN\n",
       "1126  November  27  2021   8:00  AM  -   1:00  PM  NaN NaN\n",
       "1127  December   4  2021  11:00  AM  -   8:00  PM  NaN NaN\n",
       "\n",
       "[1128 rows x 10 columns]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "455091eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hello=hello.rename(columns={0:'Month',1:'Day',2:'Year',3:'hour',4:'period'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02994c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "54582bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "hello=hello[['Year','Month','Day']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "2857b848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['February', 'March', 'April', 'May', 'June', 'July', '\\x0c',\n",
       "       'August', 'September', 'October', 'November', 'December',\n",
       "       'January', 'from', nan, '1pm-6pm'], dtype=object)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hello.Month.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "5aea60fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "hello.Month=hello.Month.replace('February',2)\n",
    "hello.Month=hello.Month.replace('March',3)\n",
    "hello.Month=hello.Month.replace('April',4)\n",
    "hello.Month=hello.Month.replace('May',5)\n",
    "hello.Month=hello.Month.replace('June',6)\n",
    "hello.Month=hello.Month.replace('July',7)\n",
    "hello.Month=hello.Month.replace('August',8)\n",
    "hello.Month=hello.Month.replace('September',9)\n",
    "hello.Month=hello.Month.replace('October',10)\n",
    "hello.Month=hello.Month.replace('November',11)\n",
    "hello.Month=hello.Month.replace('December',12)\n",
    "hello.Month=hello.Month.replace('January',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "aa1c9b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=pd.to_datetime(hello,yearfirst=True,errors='coerce',format='%D-%m-%Y-%h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "0c183193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2018-02-10\n",
       "1   2018-02-10\n",
       "2   2018-02-10\n",
       "3   2018-03-03\n",
       "4   2018-03-17\n",
       "dtype: datetime64[ns]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "37ad9689",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=df3.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "bd9f9edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.DataFrame(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "de93ef80",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of ['Date'] are in the columns\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-246-a1b2487f5cfd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdf2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'Date'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Date\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mset_index\u001b[1;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[0;32m   4725\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4726\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4727\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"None of {missing} are in the columns\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4729\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of ['Date'] are in the columns\""
     ]
    }
   ],
   "source": [
    "df2=df2.rename(columns={0:'Date'})\n",
    "df2=df2.set_index(\"Date\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "d64bf014",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=df2.resample('1min').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2616ef8",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "04d3ed60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['event']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "6db4de69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['event']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "b85f0569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-02-10 00:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-02-10 00:01:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-02-10 00:02:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-02-10 00:03:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-02-10 00:04:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005916</th>\n",
       "      <td>2021-12-03 23:56:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005917</th>\n",
       "      <td>2021-12-03 23:57:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005918</th>\n",
       "      <td>2021-12-03 23:58:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005919</th>\n",
       "      <td>2021-12-03 23:59:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005920</th>\n",
       "      <td>2021-12-04 00:00:00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2005921 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Date  event\n",
       "0       2018-02-10 00:00:00      1\n",
       "1       2018-02-10 00:01:00      1\n",
       "2       2018-02-10 00:02:00      1\n",
       "3       2018-02-10 00:03:00      1\n",
       "4       2018-02-10 00:04:00      1\n",
       "...                     ...    ...\n",
       "2005916 2021-12-03 23:56:00      1\n",
       "2005917 2021-12-03 23:57:00      1\n",
       "2005918 2021-12-03 23:58:00      1\n",
       "2005919 2021-12-03 23:59:00      1\n",
       "2005920 2021-12-04 00:00:00      1\n",
       "\n",
       "[2005921 rows x 2 columns]"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3=df3.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "c693da92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=pd.DataFrame(df3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "b6e1d5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=df3.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "8f95a617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         2018-02-10 00:00:00\n",
       "1         2018-02-10 00:01:00\n",
       "2         2018-02-10 00:02:00\n",
       "3         2018-02-10 00:03:00\n",
       "4         2018-02-10 00:04:00\n",
       "                  ...        \n",
       "2005916   2021-12-03 23:56:00\n",
       "2005917   2021-12-03 23:57:00\n",
       "2005918   2021-12-03 23:58:00\n",
       "2005919   2021-12-03 23:59:00\n",
       "2005920   2021-12-04 00:00:00\n",
       "Name: Date, Length: 2005921, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "d5e9477e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'latitude', 'longitude', 'parent_incident_type', 'log',\n",
       "       'Friday', 'Monday', 'Saturday', 'Sunday', 'Thursday', 'Tuesday',\n",
       "       'Wednesday', 'Holiday_4th of July', 'Holiday_Christmas Day',\n",
       "       'Holiday_Christmas Eve', 'Holiday_Columbus Day',\n",
       "       'Holiday_Eastern Easter', 'Holiday_Juneteenth', 'Holiday_Labor Day',\n",
       "       'Holiday_Labor Day Weekend', 'Holiday_Martin Luther King, Jr. Day',\n",
       "       'Holiday_Memorial Day', 'Holiday_New Year's Day',\n",
       "       'Holiday_New Year’s Eve', 'Holiday_Thanksgiving Day',\n",
       "       'Holiday_Thanksgiving Eve', 'Holiday_Valentine’s Day',\n",
       "       'Holiday_Veterans Day', 'Holiday_Washington's Birthday',\n",
       "       'Holiday_Western Easter'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4=pd.read_csv('data\\pre_processed.csv')\n",
    "df4.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "4af72850",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4=df4.rename(columns={'Unnamed: 0':'Date'})\n",
    "df4.Date=pd.to_datetime(df4.Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "768e77ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>parent_incident_type</th>\n",
       "      <th>log</th>\n",
       "      <th>Friday</th>\n",
       "      <th>Monday</th>\n",
       "      <th>Saturday</th>\n",
       "      <th>Sunday</th>\n",
       "      <th>Thursday</th>\n",
       "      <th>...</th>\n",
       "      <th>Holiday_Martin Luther King, Jr. Day</th>\n",
       "      <th>Holiday_Memorial Day</th>\n",
       "      <th>Holiday_New Year's Day</th>\n",
       "      <th>Holiday_New Year’s Eve</th>\n",
       "      <th>Holiday_Thanksgiving Day</th>\n",
       "      <th>Holiday_Thanksgiving Eve</th>\n",
       "      <th>Holiday_Valentine’s Day</th>\n",
       "      <th>Holiday_Veterans Day</th>\n",
       "      <th>Holiday_Washington's Birthday</th>\n",
       "      <th>Holiday_Western Easter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-01 00:00:00</td>\n",
       "      <td>42.874699</td>\n",
       "      <td>-78.823627</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-01 00:00:00</td>\n",
       "      <td>42.958426</td>\n",
       "      <td>-78.855482</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-01 00:00:00</td>\n",
       "      <td>42.948746</td>\n",
       "      <td>-78.841021</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-01 00:00:00</td>\n",
       "      <td>42.869867</td>\n",
       "      <td>-78.849571</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-01 00:00:00</td>\n",
       "      <td>42.921298</td>\n",
       "      <td>-78.891109</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196075</th>\n",
       "      <td>2021-08-30 19:10:35</td>\n",
       "      <td>42.940000</td>\n",
       "      <td>-78.851000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196076</th>\n",
       "      <td>2021-08-30 19:30:00</td>\n",
       "      <td>42.881000</td>\n",
       "      <td>-78.801000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196077</th>\n",
       "      <td>2021-08-30 21:15:00</td>\n",
       "      <td>42.919000</td>\n",
       "      <td>-78.812000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196078</th>\n",
       "      <td>2021-08-30 23:18:04</td>\n",
       "      <td>42.947000</td>\n",
       "      <td>-78.891000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196079</th>\n",
       "      <td>2021-08-31 02:35:24</td>\n",
       "      <td>42.854000</td>\n",
       "      <td>-78.827000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196080 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Date   latitude  longitude  parent_incident_type  log  \\\n",
       "0      2010-01-01 00:00:00  42.874699 -78.823627                     0    1   \n",
       "1      2010-01-01 00:00:00  42.958426 -78.855482                     0    1   \n",
       "2      2010-01-01 00:00:00  42.948746 -78.841021                     2    1   \n",
       "3      2010-01-01 00:00:00  42.869867 -78.849571                     0    1   \n",
       "4      2010-01-01 00:00:00  42.921298 -78.891109                     2    1   \n",
       "...                    ...        ...        ...                   ...  ...   \n",
       "196075 2021-08-30 19:10:35  42.940000 -78.851000                     1    1   \n",
       "196076 2021-08-30 19:30:00  42.881000 -78.801000                     0    1   \n",
       "196077 2021-08-30 21:15:00  42.919000 -78.812000                     1    1   \n",
       "196078 2021-08-30 23:18:04  42.947000 -78.891000                     0    1   \n",
       "196079 2021-08-31 02:35:24  42.854000 -78.827000                     1    1   \n",
       "\n",
       "        Friday  Monday  Saturday  Sunday  Thursday  ...  \\\n",
       "0            1       0         0       0         0  ...   \n",
       "1            1       0         0       0         0  ...   \n",
       "2            1       0         0       0         0  ...   \n",
       "3            1       0         0       0         0  ...   \n",
       "4            1       0         0       0         0  ...   \n",
       "...        ...     ...       ...     ...       ...  ...   \n",
       "196075       0       1         0       0         0  ...   \n",
       "196076       0       1         0       0         0  ...   \n",
       "196077       0       1         0       0         0  ...   \n",
       "196078       0       0         0       0         0  ...   \n",
       "196079       0       0         0       0         0  ...   \n",
       "\n",
       "        Holiday_Martin Luther King, Jr. Day  Holiday_Memorial Day  \\\n",
       "0                                       0.0                   0.0   \n",
       "1                                       0.0                   0.0   \n",
       "2                                       0.0                   0.0   \n",
       "3                                       0.0                   0.0   \n",
       "4                                       0.0                   0.0   \n",
       "...                                     ...                   ...   \n",
       "196075                                  0.0                   0.0   \n",
       "196076                                  0.0                   0.0   \n",
       "196077                                  0.0                   0.0   \n",
       "196078                                  0.0                   0.0   \n",
       "196079                                  0.0                   0.0   \n",
       "\n",
       "        Holiday_New Year's Day  Holiday_New Year’s Eve  \\\n",
       "0                          1.0                     0.0   \n",
       "1                          1.0                     0.0   \n",
       "2                          1.0                     0.0   \n",
       "3                          1.0                     0.0   \n",
       "4                          1.0                     0.0   \n",
       "...                        ...                     ...   \n",
       "196075                     0.0                     0.0   \n",
       "196076                     0.0                     0.0   \n",
       "196077                     0.0                     0.0   \n",
       "196078                     0.0                     0.0   \n",
       "196079                     0.0                     0.0   \n",
       "\n",
       "        Holiday_Thanksgiving Day  Holiday_Thanksgiving Eve  \\\n",
       "0                            0.0                       0.0   \n",
       "1                            0.0                       0.0   \n",
       "2                            0.0                       0.0   \n",
       "3                            0.0                       0.0   \n",
       "4                            0.0                       0.0   \n",
       "...                          ...                       ...   \n",
       "196075                       0.0                       0.0   \n",
       "196076                       0.0                       0.0   \n",
       "196077                       0.0                       0.0   \n",
       "196078                       0.0                       0.0   \n",
       "196079                       0.0                       0.0   \n",
       "\n",
       "        Holiday_Valentine’s Day  Holiday_Veterans Day  \\\n",
       "0                           0.0                   0.0   \n",
       "1                           0.0                   0.0   \n",
       "2                           0.0                   0.0   \n",
       "3                           0.0                   0.0   \n",
       "4                           0.0                   0.0   \n",
       "...                         ...                   ...   \n",
       "196075                      0.0                   0.0   \n",
       "196076                      0.0                   0.0   \n",
       "196077                      0.0                   0.0   \n",
       "196078                      0.0                   0.0   \n",
       "196079                      0.0                   0.0   \n",
       "\n",
       "        Holiday_Washington's Birthday  Holiday_Western Easter  \n",
       "0                                 0.0                     0.0  \n",
       "1                                 0.0                     0.0  \n",
       "2                                 0.0                     0.0  \n",
       "3                                 0.0                     0.0  \n",
       "4                                 0.0                     0.0  \n",
       "...                               ...                     ...  \n",
       "196075                            0.0                     0.0  \n",
       "196076                            0.0                     0.0  \n",
       "196077                            0.0                     0.0  \n",
       "196078                            0.0                     0.0  \n",
       "196079                            0.0                     0.0  \n",
       "\n",
       "[196080 rows x 30 columns]"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "07b96726",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4=df4.merge(df3,how='outer',on='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "990e3549",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4=df4.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "dfc4a02d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>parent_incident_type</th>\n",
       "      <th>log</th>\n",
       "      <th>Friday</th>\n",
       "      <th>Monday</th>\n",
       "      <th>Saturday</th>\n",
       "      <th>Sunday</th>\n",
       "      <th>Thursday</th>\n",
       "      <th>...</th>\n",
       "      <th>Holiday_Memorial Day</th>\n",
       "      <th>Holiday_New Year's Day</th>\n",
       "      <th>Holiday_New Year’s Eve</th>\n",
       "      <th>Holiday_Thanksgiving Day</th>\n",
       "      <th>Holiday_Thanksgiving Eve</th>\n",
       "      <th>Holiday_Valentine’s Day</th>\n",
       "      <th>Holiday_Veterans Day</th>\n",
       "      <th>Holiday_Washington's Birthday</th>\n",
       "      <th>Holiday_Western Easter</th>\n",
       "      <th>event</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-01 00:00:00</td>\n",
       "      <td>42.874699</td>\n",
       "      <td>-78.823627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-01 00:00:00</td>\n",
       "      <td>42.958426</td>\n",
       "      <td>-78.855482</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-01 00:00:00</td>\n",
       "      <td>42.948746</td>\n",
       "      <td>-78.841021</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-01 00:00:00</td>\n",
       "      <td>42.869867</td>\n",
       "      <td>-78.849571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-01 00:00:00</td>\n",
       "      <td>42.921298</td>\n",
       "      <td>-78.891109</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196075</th>\n",
       "      <td>2021-08-30 19:10:35</td>\n",
       "      <td>42.940000</td>\n",
       "      <td>-78.851000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196076</th>\n",
       "      <td>2021-08-30 19:30:00</td>\n",
       "      <td>42.881000</td>\n",
       "      <td>-78.801000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196077</th>\n",
       "      <td>2021-08-30 21:15:00</td>\n",
       "      <td>42.919000</td>\n",
       "      <td>-78.812000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196078</th>\n",
       "      <td>2021-08-30 23:18:04</td>\n",
       "      <td>42.947000</td>\n",
       "      <td>-78.891000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196079</th>\n",
       "      <td>2021-08-31 02:35:24</td>\n",
       "      <td>42.854000</td>\n",
       "      <td>-78.827000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196080 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Date   latitude  longitude  parent_incident_type  log  \\\n",
       "0      2010-01-01 00:00:00  42.874699 -78.823627                   0.0  1.0   \n",
       "1      2010-01-01 00:00:00  42.958426 -78.855482                   0.0  1.0   \n",
       "2      2010-01-01 00:00:00  42.948746 -78.841021                   2.0  1.0   \n",
       "3      2010-01-01 00:00:00  42.869867 -78.849571                   0.0  1.0   \n",
       "4      2010-01-01 00:00:00  42.921298 -78.891109                   2.0  1.0   \n",
       "...                    ...        ...        ...                   ...  ...   \n",
       "196075 2021-08-30 19:10:35  42.940000 -78.851000                   1.0  1.0   \n",
       "196076 2021-08-30 19:30:00  42.881000 -78.801000                   0.0  1.0   \n",
       "196077 2021-08-30 21:15:00  42.919000 -78.812000                   1.0  1.0   \n",
       "196078 2021-08-30 23:18:04  42.947000 -78.891000                   0.0  1.0   \n",
       "196079 2021-08-31 02:35:24  42.854000 -78.827000                   1.0  1.0   \n",
       "\n",
       "        Friday  Monday  Saturday  Sunday  Thursday  ...  Holiday_Memorial Day  \\\n",
       "0          1.0     0.0       0.0     0.0       0.0  ...                   0.0   \n",
       "1          1.0     0.0       0.0     0.0       0.0  ...                   0.0   \n",
       "2          1.0     0.0       0.0     0.0       0.0  ...                   0.0   \n",
       "3          1.0     0.0       0.0     0.0       0.0  ...                   0.0   \n",
       "4          1.0     0.0       0.0     0.0       0.0  ...                   0.0   \n",
       "...        ...     ...       ...     ...       ...  ...                   ...   \n",
       "196075     0.0     1.0       0.0     0.0       0.0  ...                   0.0   \n",
       "196076     0.0     1.0       0.0     0.0       0.0  ...                   0.0   \n",
       "196077     0.0     1.0       0.0     0.0       0.0  ...                   0.0   \n",
       "196078     0.0     0.0       0.0     0.0       0.0  ...                   0.0   \n",
       "196079     0.0     0.0       0.0     0.0       0.0  ...                   0.0   \n",
       "\n",
       "        Holiday_New Year's Day  Holiday_New Year’s Eve  \\\n",
       "0                          1.0                     0.0   \n",
       "1                          1.0                     0.0   \n",
       "2                          1.0                     0.0   \n",
       "3                          1.0                     0.0   \n",
       "4                          1.0                     0.0   \n",
       "...                        ...                     ...   \n",
       "196075                     0.0                     0.0   \n",
       "196076                     0.0                     0.0   \n",
       "196077                     0.0                     0.0   \n",
       "196078                     0.0                     0.0   \n",
       "196079                     0.0                     0.0   \n",
       "\n",
       "        Holiday_Thanksgiving Day  Holiday_Thanksgiving Eve  \\\n",
       "0                            0.0                       0.0   \n",
       "1                            0.0                       0.0   \n",
       "2                            0.0                       0.0   \n",
       "3                            0.0                       0.0   \n",
       "4                            0.0                       0.0   \n",
       "...                          ...                       ...   \n",
       "196075                       0.0                       0.0   \n",
       "196076                       0.0                       0.0   \n",
       "196077                       0.0                       0.0   \n",
       "196078                       0.0                       0.0   \n",
       "196079                       0.0                       0.0   \n",
       "\n",
       "        Holiday_Valentine’s Day  Holiday_Veterans Day  \\\n",
       "0                           0.0                   0.0   \n",
       "1                           0.0                   0.0   \n",
       "2                           0.0                   0.0   \n",
       "3                           0.0                   0.0   \n",
       "4                           0.0                   0.0   \n",
       "...                         ...                   ...   \n",
       "196075                      0.0                   0.0   \n",
       "196076                      0.0                   0.0   \n",
       "196077                      0.0                   0.0   \n",
       "196078                      0.0                   0.0   \n",
       "196079                      0.0                   0.0   \n",
       "\n",
       "        Holiday_Washington's Birthday  Holiday_Western Easter  event  \n",
       "0                                 0.0                     0.0    0.0  \n",
       "1                                 0.0                     0.0    0.0  \n",
       "2                                 0.0                     0.0    0.0  \n",
       "3                                 0.0                     0.0    0.0  \n",
       "4                                 0.0                     0.0    0.0  \n",
       "...                               ...                     ...    ...  \n",
       "196075                            0.0                     0.0    0.0  \n",
       "196076                            0.0                     0.0    1.0  \n",
       "196077                            0.0                     0.0    1.0  \n",
       "196078                            0.0                     0.0    0.0  \n",
       "196079                            0.0                     0.0    0.0  \n",
       "\n",
       "[196080 rows x 31 columns]"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "01a6301a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.event=df4.event.replace(np.nan,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "92ef7b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.to_csv('data\\events_Added.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "e9962012",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4['Date']=pd.to_datetime(df4.Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "f9d69098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>parent_incident_type</th>\n",
       "      <th>log</th>\n",
       "      <th>Friday</th>\n",
       "      <th>Monday</th>\n",
       "      <th>Saturday</th>\n",
       "      <th>Sunday</th>\n",
       "      <th>Thursday</th>\n",
       "      <th>Tuesday</th>\n",
       "      <th>...</th>\n",
       "      <th>Holiday_Valentine’s Day</th>\n",
       "      <th>Holiday_Veterans Day</th>\n",
       "      <th>Holiday_Washington's Birthday</th>\n",
       "      <th>Holiday_Western Easter</th>\n",
       "      <th>event</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-01 00:00:00</th>\n",
       "      <td>42.874699</td>\n",
       "      <td>-78.823627</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-01 00:00:00</th>\n",
       "      <td>42.958426</td>\n",
       "      <td>-78.855482</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-01 00:00:00</th>\n",
       "      <td>42.948746</td>\n",
       "      <td>-78.841021</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-01 00:00:00</th>\n",
       "      <td>42.869867</td>\n",
       "      <td>-78.849571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-01 00:00:00</th>\n",
       "      <td>42.921298</td>\n",
       "      <td>-78.891109</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-30 19:10:35</th>\n",
       "      <td>42.940000</td>\n",
       "      <td>-78.851000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>19</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-30 19:30:00</th>\n",
       "      <td>42.881000</td>\n",
       "      <td>-78.801000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>19</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-30 21:15:00</th>\n",
       "      <td>42.919000</td>\n",
       "      <td>-78.812000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-30 23:18:04</th>\n",
       "      <td>42.947000</td>\n",
       "      <td>-78.891000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-31 02:35:24</th>\n",
       "      <td>42.854000</td>\n",
       "      <td>-78.827000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021</td>\n",
       "      <td>8</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>196080 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      latitude  longitude  parent_incident_type  log  Friday  \\\n",
       "Date                                                                           \n",
       "2010-01-01 00:00:00  42.874699 -78.823627                   0.0  1.0     1.0   \n",
       "2010-01-01 00:00:00  42.958426 -78.855482                   0.0  1.0     1.0   \n",
       "2010-01-01 00:00:00  42.948746 -78.841021                   2.0  1.0     1.0   \n",
       "2010-01-01 00:00:00  42.869867 -78.849571                   0.0  1.0     1.0   \n",
       "2010-01-01 00:00:00  42.921298 -78.891109                   2.0  1.0     1.0   \n",
       "...                        ...        ...                   ...  ...     ...   \n",
       "2021-08-30 19:10:35  42.940000 -78.851000                   1.0  1.0     0.0   \n",
       "2021-08-30 19:30:00  42.881000 -78.801000                   0.0  1.0     0.0   \n",
       "2021-08-30 21:15:00  42.919000 -78.812000                   1.0  1.0     0.0   \n",
       "2021-08-30 23:18:04  42.947000 -78.891000                   0.0  1.0     0.0   \n",
       "2021-08-31 02:35:24  42.854000 -78.827000                   1.0  1.0     0.0   \n",
       "\n",
       "                     Monday  Saturday  Sunday  Thursday  Tuesday  ...  \\\n",
       "Date                                                              ...   \n",
       "2010-01-01 00:00:00     0.0       0.0     0.0       0.0      0.0  ...   \n",
       "2010-01-01 00:00:00     0.0       0.0     0.0       0.0      0.0  ...   \n",
       "2010-01-01 00:00:00     0.0       0.0     0.0       0.0      0.0  ...   \n",
       "2010-01-01 00:00:00     0.0       0.0     0.0       0.0      0.0  ...   \n",
       "2010-01-01 00:00:00     0.0       0.0     0.0       0.0      0.0  ...   \n",
       "...                     ...       ...     ...       ...      ...  ...   \n",
       "2021-08-30 19:10:35     1.0       0.0     0.0       0.0      0.0  ...   \n",
       "2021-08-30 19:30:00     1.0       0.0     0.0       0.0      0.0  ...   \n",
       "2021-08-30 21:15:00     1.0       0.0     0.0       0.0      0.0  ...   \n",
       "2021-08-30 23:18:04     0.0       0.0     0.0       0.0      1.0  ...   \n",
       "2021-08-31 02:35:24     0.0       0.0     0.0       0.0      1.0  ...   \n",
       "\n",
       "                     Holiday_Valentine’s Day  Holiday_Veterans Day  \\\n",
       "Date                                                                 \n",
       "2010-01-01 00:00:00                      0.0                   0.0   \n",
       "2010-01-01 00:00:00                      0.0                   0.0   \n",
       "2010-01-01 00:00:00                      0.0                   0.0   \n",
       "2010-01-01 00:00:00                      0.0                   0.0   \n",
       "2010-01-01 00:00:00                      0.0                   0.0   \n",
       "...                                      ...                   ...   \n",
       "2021-08-30 19:10:35                      0.0                   0.0   \n",
       "2021-08-30 19:30:00                      0.0                   0.0   \n",
       "2021-08-30 21:15:00                      0.0                   0.0   \n",
       "2021-08-30 23:18:04                      0.0                   0.0   \n",
       "2021-08-31 02:35:24                      0.0                   0.0   \n",
       "\n",
       "                     Holiday_Washington's Birthday  Holiday_Western Easter  \\\n",
       "Date                                                                         \n",
       "2010-01-01 00:00:00                            0.0                     0.0   \n",
       "2010-01-01 00:00:00                            0.0                     0.0   \n",
       "2010-01-01 00:00:00                            0.0                     0.0   \n",
       "2010-01-01 00:00:00                            0.0                     0.0   \n",
       "2010-01-01 00:00:00                            0.0                     0.0   \n",
       "...                                            ...                     ...   \n",
       "2021-08-30 19:10:35                            0.0                     0.0   \n",
       "2021-08-30 19:30:00                            0.0                     0.0   \n",
       "2021-08-30 21:15:00                            0.0                     0.0   \n",
       "2021-08-30 23:18:04                            0.0                     0.0   \n",
       "2021-08-31 02:35:24                            0.0                     0.0   \n",
       "\n",
       "                     event  year  month  day  hour  minute  \n",
       "Date                                                        \n",
       "2010-01-01 00:00:00    0.0  2010      1    1     0       0  \n",
       "2010-01-01 00:00:00    0.0  2010      1    1     0       0  \n",
       "2010-01-01 00:00:00    0.0  2010      1    1     0       0  \n",
       "2010-01-01 00:00:00    0.0  2010      1    1     0       0  \n",
       "2010-01-01 00:00:00    0.0  2010      1    1     0       0  \n",
       "...                    ...   ...    ...  ...   ...     ...  \n",
       "2021-08-30 19:10:35    0.0  2021      8   30    19      10  \n",
       "2021-08-30 19:30:00    1.0  2021      8   30    19      30  \n",
       "2021-08-30 21:15:00    1.0  2021      8   30    21      15  \n",
       "2021-08-30 23:18:04    0.0  2021      8   30    23      18  \n",
       "2021-08-31 02:35:24    0.0  2021      8   31     2      35  \n",
       "\n",
       "[196080 rows x 35 columns]"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fa877c",
   "metadata": {},
   "source": [
    "# Making dt feature as a set of seperate features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "d15d7916",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4['year']=df4.Date.dt.year\n",
    "df4['month']=df4.Date.dt.month\n",
    "df4['day']=df4.Date.dt.day\n",
    "df4['hour']=df4.Date.dt.hour\n",
    "df4['minute']=df4.Date.dt.minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "2355e4cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(196080, 35)"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "7dee5755",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4=df4.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "2f127302",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df4.drop('parent_incident_type',axis=1).values\n",
    "Y=df4.parent_incident_type.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "ceb4903e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-447-d900e9248590>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-447-d900e9248590>\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    keras.layers.Dense(1, activation='sigmoid\u001b[0m\n\u001b[1;37m                                             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "def ANN1(X_train, y_train, X_test, y_test, loss, weights):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(34 ,input_dim=34,activation='relu'),\n",
    "        keras.layers.Dense(52, activation='relu'),\n",
    "        keras.layers.Dense(28, activation='relu'),\n",
    "        keras.layers.Dense(1, activation='sigmoid\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n",
    "    \n",
    "    if weights == -1:\n",
    "        model.fit(X_train, y_train, epochs=100)\n",
    "    else:\n",
    "        model.fit(X_train, y_train, epochs=100,class_weight = weights)\n",
    "    \n",
    "    print(model.evaluate(X_test, y_test))\n",
    "    \n",
    "    y_preds = model.predict(X_test)\n",
    "    y_preds = np.round(y_preds)\n",
    "    \n",
    "    print(\"Classification Report: \\n\", classification_report(y_test, y_preds))\n",
    "    \n",
    "    return y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "5051e10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2795/2795 [==============================] - 1s 497us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 2/50\n",
      "2795/2795 [==============================] - 1s 503us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 3/50\n",
      "2795/2795 [==============================] - 1s 512us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 4/50\n",
      "2795/2795 [==============================] - 1s 506us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 5/50\n",
      "2795/2795 [==============================] - 1s 503us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 6/50\n",
      "2795/2795 [==============================] - 1s 496us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 7/50\n",
      "2795/2795 [==============================] - 1s 497us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 8/50\n",
      "2795/2795 [==============================] - 1s 500us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 9/50\n",
      "2795/2795 [==============================] - 1s 504us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 10/50\n",
      "2795/2795 [==============================] - 1s 496us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 11/50\n",
      "2795/2795 [==============================] - 1s 489us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 12/50\n",
      "2795/2795 [==============================] - 1s 494us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 13/50\n",
      "2795/2795 [==============================] - 1s 498us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 14/50\n",
      "2795/2795 [==============================] - 1s 498us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 15/50\n",
      "2795/2795 [==============================] - 1s 499us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 16/50\n",
      "2795/2795 [==============================] - 1s 499us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 17/50\n",
      "2795/2795 [==============================] - 1s 497us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 18/50\n",
      "2795/2795 [==============================] - 1s 492us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 19/50\n",
      "2795/2795 [==============================] - 1s 490us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 20/50\n",
      "2795/2795 [==============================] - 1s 490us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 21/50\n",
      "2795/2795 [==============================] - 1s 491us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 22/50\n",
      "2795/2795 [==============================] - 1s 490us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 23/50\n",
      "2795/2795 [==============================] - 1s 491us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 24/50\n",
      "2795/2795 [==============================] - 1s 492us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 25/50\n",
      "2795/2795 [==============================] - 1s 491us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 26/50\n",
      "2795/2795 [==============================] - 1s 500us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 27/50\n",
      "2795/2795 [==============================] - 1s 489us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 28/50\n",
      "2795/2795 [==============================] - 1s 488us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 29/50\n",
      "2795/2795 [==============================] - 1s 486us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 30/50\n",
      "2795/2795 [==============================] - 1s 488us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 31/50\n",
      "2795/2795 [==============================] - 1s 492us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 32/50\n",
      "2795/2795 [==============================] - 1s 489us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 33/50\n",
      "2795/2795 [==============================] - 1s 488us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 34/50\n",
      "2795/2795 [==============================] - 1s 485us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 35/50\n",
      "2795/2795 [==============================] - 1s 488us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 36/50\n",
      "2795/2795 [==============================] - 1s 489us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 37/50\n",
      "2795/2795 [==============================] - 1s 490us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 38/50\n",
      "2795/2795 [==============================] - 1s 495us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 39/50\n",
      "2795/2795 [==============================] - 1s 492us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 40/50\n",
      "2795/2795 [==============================] - 1s 488us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 41/50\n",
      "2795/2795 [==============================] - 1s 491us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 42/50\n",
      "2795/2795 [==============================] - 1s 488us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 43/50\n",
      "2795/2795 [==============================] - 1s 488us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 44/50\n",
      "2795/2795 [==============================] - 1s 490us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 45/50\n",
      "2795/2795 [==============================] - 1s 488us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 46/50\n",
      "2795/2795 [==============================] - 1s 491us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 47/50\n",
      "2795/2795 [==============================] - 1s 488us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 48/50\n",
      "2795/2795 [==============================] - 1s 491us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 49/50\n",
      "2795/2795 [==============================] - 1s 491us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 50/50\n",
      "2795/2795 [==============================] - 1s 498us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "699/699 [==============================] - 0s 328us/step - loss: 6.5572e-08 - accuracy: 0.4862\n",
      "[6.5571505558637e-08, 0.4861782193183899]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00     10773\n",
      "         1.0       0.49      1.00      0.65     10869\n",
      "         2.0       0.00      0.00      0.00       714\n",
      "\n",
      "    accuracy                           0.49     22356\n",
      "   macro avg       0.16      0.33      0.22     22356\n",
      "weighted avg       0.24      0.49      0.32     22356\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmioi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\mmioi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\mmioi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       ...,\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANN1(X_train, y_train, X_test, y_test,\"categorical_crossentropy\", -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "a866ad3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  200\n",
      "Accuracy score (training): 0.707\n",
      "Accuracy score (validation): 0.702\n",
      "\n",
      "Learning rate:  400\n",
      "Accuracy score (training): 0.707\n",
      "Accuracy score (validation): 0.702\n",
      "\n",
      "Learning rate:  600\n",
      "Accuracy score (training): 0.707\n",
      "Accuracy score (validation): 0.702\n",
      "\n",
      "Learning rate:  1000\n",
      "Accuracy score (training): 0.707\n",
      "Accuracy score (validation): 0.702\n",
      "\n",
      "Learning rate:  2000\n",
      "Accuracy score (training): 0.707\n",
      "Accuracy score (validation): 0.702\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_e = [200,400, 600, 1000, 2000]\n",
    "\n",
    "for n in n_e:\n",
    "    from sklearn.ensemble import RandomForestClassifier as rf\n",
    "    rf = rf(n_estimators=n, max_depth = 5, random_state = 0,bootstrap=False,criterion='gini')\n",
    "    rf.fit(X_train, y_train)\n",
    "    print(\"Learning rate: \", n)\n",
    "    print(\"Accuracy score (training): {0:.3f}\".format(rf.score(X_train, y_train)))\n",
    "    print(\"Accuracy score (validation): {0:.3f}\".format(rf.score(X_test, y_test)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "bee54027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.05\n",
      "Accuracy score (training): 0.714\n",
      "Accuracy score (validation): 0.710\n",
      "\n",
      "Learning rate:  0.1\n",
      "Accuracy score (training): 0.721\n",
      "Accuracy score (validation): 0.718\n",
      "\n",
      "Learning rate:  0.25\n",
      "Accuracy score (training): 0.728\n",
      "Accuracy score (validation): 0.726\n",
      "\n",
      "Learning rate:  0.5\n",
      "Accuracy score (training): 0.730\n",
      "Accuracy score (validation): 0.727\n",
      "\n",
      "Learning rate:  0.75\n",
      "Accuracy score (training): 0.732\n",
      "Accuracy score (validation): 0.727\n",
      "\n",
      "Learning rate:  1\n",
      "Accuracy score (training): 0.733\n",
      "Accuracy score (validation): 0.729\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [0.05, 0.1, 0.25, 0.5, 0.75, 1]\n",
    "for learning_rate in learning_rates:\n",
    "    gb = GradientBoostingClassifier(n_estimators=200, learning_rate = learning_rate, max_features=5, max_depth = 2, random_state = 0)\n",
    "    gb.fit(X_train, y_train)\n",
    "    print(\"Learning rate: \", learning_rate)\n",
    "    print(\"Accuracy score (training): {0:.3f}\".format(gb.score(X_train, y_train)))\n",
    "    print(\"Accuracy score (validation): {0:.3f}\".format(gb.score(X_test, y_test)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "9b676923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  1\n",
      "Accuracy score (training): 0.733\n",
      "Accuracy score (validation): 0.729\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(n_estimators=200, learning_rate = 1, max_features=5, max_depth = 2, random_state = 0)\n",
    "gb.fit(X_train, y_train)\n",
    "print(\"Learning rate: \", learning_rate)\n",
    "print(\"Accuracy score (training): {0:.3f}\".format(gb.score(X_train, y_train)))\n",
    "print(\"Accuracy score (validation): {0:.3f}\".format(gb.score(X_test, y_test)))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "562e32f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.92      0.83     27525\n",
      "         1.0       0.59      0.29      0.39     10958\n",
      "         2.0       0.09      0.00      0.00       733\n",
      "\n",
      "    accuracy                           0.73     39216\n",
      "   macro avg       0.48      0.41      0.41     39216\n",
      "weighted avg       0.69      0.73      0.69     39216\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ypred=gb.predict(X_test)\n",
    "print(classification_report(y_test,ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d589ab06",
   "metadata": {},
   "source": [
    "the Classification work seems to be getting better , right now the predictor is strating to make predictions that are not only property crimes but at the whole set. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9e294c",
   "metadata": {},
   "source": [
    "# Balancing the data again "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "01615cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random under-sampling:\n",
      "0.0    54166\n",
      "1.0    54166\n",
      "2.0     3447\n",
      "Name: parent_incident_type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "count_class_0, count_class_1 ,count_class_2= df4.parent_incident_type.value_counts()\n",
    "df_class_0 = df4[df4['parent_incident_type'] == 0]\n",
    "df_class_1 = df4[df4['parent_incident_type'] == 1]\n",
    "df_class_2 = df4[df4['parent_incident_type'] == 2]\n",
    "# Undersample 0-class and concat the DataFrames of both class\n",
    "df_class_0_under = df_class_0.sample(count_class_1)\n",
    "df_test_under = pd.concat([df_class_0_under, df_class_1,df_class_2], axis=0)\n",
    "\n",
    "print('Random under-sampling:')\n",
    "print(df_test_under.parent_incident_type.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "b6df0055",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_test_under.drop('parent_incident_type',axis=1).values\n",
    "Y=df_test_under.parent_incident_type.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.4, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "8c0c16a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2795/2795 [==============================] - 2s 541us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 2/50\n",
      "2795/2795 [==============================] - 2s 542us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 3/50\n",
      "2795/2795 [==============================] - 2s 551us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 4/50\n",
      "2795/2795 [==============================] - 2s 546us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 5/50\n",
      "2795/2795 [==============================] - 2s 545us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 6/50\n",
      "2795/2795 [==============================] - 2s 542us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 7/50\n",
      "2795/2795 [==============================] - 1s 527us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 8/50\n",
      "2795/2795 [==============================] - 2s 550us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 9/50\n",
      "2795/2795 [==============================] - 1s 532us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 10/50\n",
      "2795/2795 [==============================] - 2s 540us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 11/50\n",
      "2795/2795 [==============================] - 2s 540us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 12/50\n",
      "2795/2795 [==============================] - 2s 554us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 13/50\n",
      "2795/2795 [==============================] - 2s 561us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 14/50\n",
      "2795/2795 [==============================] - 2s 543us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 15/50\n",
      "2795/2795 [==============================] - 2s 543us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 16/50\n",
      "2795/2795 [==============================] - 2s 546us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 17/50\n",
      "2795/2795 [==============================] - 2s 541us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 18/50\n",
      "2795/2795 [==============================] - 2s 547us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 19/50\n",
      "2795/2795 [==============================] - 2s 540us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 20/50\n",
      "2795/2795 [==============================] - 2s 551us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 21/50\n",
      "2795/2795 [==============================] - 1s 533us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 22/50\n",
      "2795/2795 [==============================] - 1s 529us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 23/50\n",
      "2795/2795 [==============================] - 1s 533us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 24/50\n",
      "2795/2795 [==============================] - 2s 545us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 25/50\n",
      "2795/2795 [==============================] - 2s 545us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 26/50\n",
      "2795/2795 [==============================] - 2s 547us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 27/50\n",
      "2795/2795 [==============================] - 2s 547us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 28/50\n",
      "2795/2795 [==============================] - 1s 536us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 29/50\n",
      "2795/2795 [==============================] - 2s 552us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 30/50\n",
      "2795/2795 [==============================] - 2s 561us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 31/50\n",
      "2795/2795 [==============================] - 2s 557us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 32/50\n",
      "2795/2795 [==============================] - 2s 548us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 33/50\n",
      "2795/2795 [==============================] - 2s 542us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 34/50\n",
      "2795/2795 [==============================] - 2s 541us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 35/50\n",
      "2795/2795 [==============================] - 2s 548us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 36/50\n",
      "2795/2795 [==============================] - 1s 532us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 37/50\n",
      "2795/2795 [==============================] - 2s 544us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 38/50\n",
      "2795/2795 [==============================] - 1s 530us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 39/50\n",
      "2795/2795 [==============================] - 2s 547us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 40/50\n",
      "2795/2795 [==============================] - 1s 529us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 41/50\n",
      "2795/2795 [==============================] - 2s 562us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 42/50\n",
      "2795/2795 [==============================] - 2s 537us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 43/50\n",
      "2795/2795 [==============================] - 2s 553us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 44/50\n",
      "2795/2795 [==============================] - 2s 556us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 45/50\n",
      "2795/2795 [==============================] - 2s 546us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 46/50\n",
      "2795/2795 [==============================] - 2s 544us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 47/50\n",
      "2795/2795 [==============================] - 1s 531us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 48/50\n",
      "2795/2795 [==============================] - 2s 540us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 49/50\n",
      "2795/2795 [==============================] - 2s 547us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "Epoch 50/50\n",
      "2795/2795 [==============================] - 1s 533us/step - loss: 6.5006e-08 - accuracy: 0.4842\n",
      "699/699 [==============================] - 0s 341us/step - loss: 6.5572e-08 - accuracy: 0.4862\n",
      "[6.5571505558637e-08, 0.4861782193183899]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00     10773\n",
      "         1.0       0.49      1.00      0.65     10869\n",
      "         2.0       0.00      0.00      0.00       714\n",
      "\n",
      "    accuracy                           0.49     22356\n",
      "   macro avg       0.16      0.33      0.22     22356\n",
      "weighted avg       0.24      0.49      0.32     22356\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmioi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\mmioi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\mmioi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       ...,\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANN1(X_train, y_train, X_test, y_test,\"categorical_crossentropy\", -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "52ca0408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  20\n",
      "Accuracy score (training): 0.638\n",
      "Accuracy score (validation): 0.643\n",
      "\n",
      "Learning rate:  40\n",
      "Accuracy score (training): 0.636\n",
      "Accuracy score (validation): 0.640\n",
      "\n",
      "Learning rate:  60\n",
      "Accuracy score (training): 0.636\n",
      "Accuracy score (validation): 0.640\n",
      "\n",
      "Learning rate:  100\n",
      "Accuracy score (training): 0.640\n",
      "Accuracy score (validation): 0.643\n",
      "\n",
      "Learning rate:  200\n",
      "Accuracy score (training): 0.640\n",
      "Accuracy score (validation): 0.644\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_e = [20,40, 60, 100, 200]\n",
    "\n",
    "for n in n_e:\n",
    "    from sklearn.ensemble import RandomForestClassifier as rf\n",
    "    rf = rf(n_estimators=n, max_depth = 5, random_state = 0,bootstrap=False,criterion='gini')\n",
    "    rf.fit(X_train, y_train)\n",
    "    print(\"Learning rate: \", n)\n",
    "    print(\"Accuracy score (training): {0:.3f}\".format(rf.score(X_train, y_train)))\n",
    "    print(\"Accuracy score (validation): {0:.3f}\".format(rf.score(X_test, y_test)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "9c62ae20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.05\n",
      "Accuracy score (training): 0.645\n",
      "Accuracy score (validation): 0.650\n",
      "\n",
      "Learning rate:  0.1\n",
      "Accuracy score (training): 0.655\n",
      "Accuracy score (validation): 0.660\n",
      "\n",
      "Learning rate:  0.25\n",
      "Accuracy score (training): 0.661\n",
      "Accuracy score (validation): 0.664\n",
      "\n",
      "Learning rate:  0.5\n",
      "Accuracy score (training): 0.666\n",
      "Accuracy score (validation): 0.667\n",
      "\n",
      "Learning rate:  0.75\n",
      "Accuracy score (training): 0.669\n",
      "Accuracy score (validation): 0.669\n",
      "\n",
      "Learning rate:  1\n",
      "Accuracy score (training): 0.670\n",
      "Accuracy score (validation): 0.668\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [0.05, 0.1, 0.25, 0.5, 0.75, 1]\n",
    "for learning_rate in learning_rates:\n",
    "    gb = GradientBoostingClassifier(n_estimators=200, learning_rate = learning_rate, max_features=5, max_depth = 2, random_state =0)\n",
    "    gb.fit(X_train, y_train)\n",
    "    print(\"Learning rate: \", learning_rate)\n",
    "    print(\"Accuracy score (training): {0:.3f}\".format(gb.score(X_train, y_train)))\n",
    "    print(\"Accuracy score (validation): {0:.3f}\".format(gb.score(X_test, y_test)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3b28de",
   "metadata": {},
   "source": [
    "# Random state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "3620727b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.67      0.67     21580\n",
      "         1.0       0.67      0.70      0.69     21773\n",
      "         2.0       0.27      0.01      0.01      1359\n",
      "\n",
      "    accuracy                           0.67     44712\n",
      "   macro avg       0.54      0.46      0.46     44712\n",
      "weighted avg       0.66      0.67      0.66     44712\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(n_estimators=200, learning_rate = 1, max_features=5, max_depth = 2, random_state =42)\n",
    "gb.fit(X_train, y_train)\n",
    "ypred=gb.predict(X_test)\n",
    "print(classification_report(y_test,ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552b1336",
   "metadata": {},
   "source": [
    "# NON Random State "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "0bb4ef49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.67      0.67     21580\n",
      "         1.0       0.67      0.70      0.68     21773\n",
      "         2.0       0.19      0.00      0.01      1359\n",
      "\n",
      "    accuracy                           0.66     44712\n",
      "   macro avg       0.51      0.46      0.45     44712\n",
      "weighted avg       0.65      0.66      0.65     44712\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier(n_estimators=200, learning_rate = 1, max_features=5, max_depth = 2, random_state =0)\n",
    "gb.fit(X_train, y_train)\n",
    "ypred=gb.predict(X_test)\n",
    "print(classification_report(y_test,ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4a9fcf",
   "metadata": {},
   "source": [
    "# Subsetting the DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "e6fd0dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsets=df4.loc['01-01-2018':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "19a22270",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=subsets.drop('parent_incident_type',axis=1).values\n",
    "y=subsets.parent_incident_type.values\n",
    "x_train, x_test, Y_train, Y_test = train_test_split(x, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "bfb68e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.05\n",
      "Accuracy score (training): 0.707\n",
      "Accuracy score (validation): 0.698\n",
      "\n",
      "Learning rate:  0.1\n",
      "Accuracy score (training): 0.714\n",
      "Accuracy score (validation): 0.703\n",
      "\n",
      "Learning rate:  0.25\n",
      "Accuracy score (training): 0.721\n",
      "Accuracy score (validation): 0.709\n",
      "\n",
      "Learning rate:  0.5\n",
      "Accuracy score (training): 0.727\n",
      "Accuracy score (validation): 0.710\n",
      "\n",
      "Learning rate:  0.75\n",
      "Accuracy score (training): 0.728\n",
      "Accuracy score (validation): 0.712\n",
      "\n",
      "Learning rate:  1\n",
      "Accuracy score (training): 0.732\n",
      "Accuracy score (validation): 0.711\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [0.05, 0.1, 0.25, 0.5, 0.75, 1]\n",
    "for learning_rate in learning_rates:\n",
    "    gb = GradientBoostingClassifier(n_estimators=200, learning_rate = learning_rate, max_features=5, max_depth = 2, random_state =0)\n",
    "    gb.fit(x_train, Y_train)\n",
    "    print(\"Learning rate: \", learning_rate)\n",
    "    print(\"Accuracy score (training): {0:.3f}\".format(gb.score(x_train, Y_train)))\n",
    "    print(\"Accuracy score (validation): {0:.3f}\".format(gb.score(x_test, Y_test)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "61cd9fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1200/1200 [==============================] - 1s 514us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 2/100\n",
      "1200/1200 [==============================] - 1s 508us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 3/100\n",
      "1200/1200 [==============================] - 1s 508us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 4/100\n",
      "1200/1200 [==============================] - 1s 501us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 5/100\n",
      "1200/1200 [==============================] - 1s 503us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 6/100\n",
      "1200/1200 [==============================] - 1s 505us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 7/100\n",
      "1200/1200 [==============================] - 1s 507us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 8/100\n",
      "1200/1200 [==============================] - 1s 510us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 9/100\n",
      "1200/1200 [==============================] - 1s 504us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 10/100\n",
      "1200/1200 [==============================] - 1s 503us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 11/100\n",
      "1200/1200 [==============================] - 1s 509us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 12/100\n",
      "1200/1200 [==============================] - 1s 509us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 13/100\n",
      "1200/1200 [==============================] - 1s 508us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 14/100\n",
      "1200/1200 [==============================] - 1s 506us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 15/100\n",
      "1200/1200 [==============================] - 1s 504us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 16/100\n",
      "1200/1200 [==============================] - 1s 524us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 17/100\n",
      "1200/1200 [==============================] - 1s 509us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 18/100\n",
      "1200/1200 [==============================] - 1s 506us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 19/100\n",
      "1200/1200 [==============================] - 1s 505us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 20/100\n",
      "1200/1200 [==============================] - 1s 508us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 21/100\n",
      "1200/1200 [==============================] - 1s 510us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 22/100\n",
      "1200/1200 [==============================] - 1s 505us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 23/100\n",
      "1200/1200 [==============================] - 1s 505us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 24/100\n",
      "1200/1200 [==============================] - 1s 505us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 25/100\n",
      "1200/1200 [==============================] - 1s 510us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 26/100\n",
      "1200/1200 [==============================] - 1s 504us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 27/100\n",
      "1200/1200 [==============================] - 1s 501us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 28/100\n",
      "1200/1200 [==============================] - 1s 502us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 29/100\n",
      "1200/1200 [==============================] - 1s 509us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 30/100\n",
      "1200/1200 [==============================] - 1s 510us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 31/100\n",
      "1200/1200 [==============================] - 1s 506us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 32/100\n",
      "1200/1200 [==============================] - 1s 506us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 33/100\n",
      "1200/1200 [==============================] - 1s 505us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 34/100\n",
      "1200/1200 [==============================] - 1s 501us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 35/100\n",
      "1200/1200 [==============================] - 1s 502us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 36/100\n",
      "1200/1200 [==============================] - 1s 505us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 37/100\n",
      "1200/1200 [==============================] - 1s 513us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 38/100\n",
      "1200/1200 [==============================] - 1s 515us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 39/100\n",
      "1200/1200 [==============================] - 1s 512us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 40/100\n",
      "1200/1200 [==============================] - 1s 505us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 41/100\n",
      "1200/1200 [==============================] - 1s 511us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 42/100\n",
      "1200/1200 [==============================] - 1s 515us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 43/100\n",
      "1200/1200 [==============================] - 1s 512us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 44/100\n",
      "1200/1200 [==============================] - 1s 501us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 45/100\n",
      "1200/1200 [==============================] - 1s 510us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 46/100\n",
      "1200/1200 [==============================] - 1s 506us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 47/100\n",
      "1200/1200 [==============================] - 1s 504us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 48/100\n",
      "1200/1200 [==============================] - 1s 504us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 49/100\n",
      "1200/1200 [==============================] - 1s 515us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 50/100\n",
      "1200/1200 [==============================] - 1s 508us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 51/100\n",
      "1200/1200 [==============================] - 1s 509us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 52/100\n",
      "1200/1200 [==============================] - 1s 505us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 53/100\n",
      "1200/1200 [==============================] - 1s 503us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 54/100\n",
      "1200/1200 [==============================] - 1s 496us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 55/100\n",
      "1200/1200 [==============================] - 1s 503us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 56/100\n",
      "1200/1200 [==============================] - 1s 500us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 57/100\n",
      "1200/1200 [==============================] - 1s 504us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 58/100\n",
      "1200/1200 [==============================] - 1s 503us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 59/100\n",
      "1200/1200 [==============================] - 1s 506us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 60/100\n",
      "1200/1200 [==============================] - 1s 505us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 61/100\n",
      "1200/1200 [==============================] - 1s 502us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 62/100\n",
      "1200/1200 [==============================] - 1s 506us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 63/100\n",
      "1200/1200 [==============================] - 1s 514us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 64/100\n",
      "1200/1200 [==============================] - 1s 510us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 65/100\n",
      "1200/1200 [==============================] - 1s 506us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 66/100\n",
      "1200/1200 [==============================] - 1s 503us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 67/100\n",
      "1200/1200 [==============================] - 1s 500us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 68/100\n",
      "1200/1200 [==============================] - 1s 517us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 69/100\n",
      "1200/1200 [==============================] - 1s 527us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 70/100\n",
      "1200/1200 [==============================] - 1s 516us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 71/100\n",
      "1200/1200 [==============================] - 1s 518us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 72/100\n",
      "1200/1200 [==============================] - 1s 510us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 73/100\n",
      "1200/1200 [==============================] - 1s 506us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 74/100\n",
      "1200/1200 [==============================] - 1s 505us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 75/100\n",
      "1200/1200 [==============================] - 1s 515us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 76/100\n",
      "1200/1200 [==============================] - 1s 511us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 77/100\n",
      "1200/1200 [==============================] - 1s 519us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200/1200 [==============================] - 1s 518us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 79/100\n",
      "1200/1200 [==============================] - 1s 516us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 80/100\n",
      "1200/1200 [==============================] - 1s 506us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 81/100\n",
      "1200/1200 [==============================] - 1s 498us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 82/100\n",
      "1200/1200 [==============================] - 1s 503us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 83/100\n",
      "1200/1200 [==============================] - 1s 500us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 84/100\n",
      "1200/1200 [==============================] - 1s 498us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 85/100\n",
      "1200/1200 [==============================] - 1s 508us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 86/100\n",
      "1200/1200 [==============================] - 1s 501us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 87/100\n",
      "1200/1200 [==============================] - 1s 505us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 88/100\n",
      "1200/1200 [==============================] - 1s 503us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 89/100\n",
      "1200/1200 [==============================] - 1s 499us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 90/100\n",
      "1200/1200 [==============================] - 1s 505us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 91/100\n",
      "1200/1200 [==============================] - 1s 509us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 92/100\n",
      "1200/1200 [==============================] - 1s 508us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 93/100\n",
      "1200/1200 [==============================] - 1s 505us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 94/100\n",
      "1200/1200 [==============================] - 1s 505us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 95/100\n",
      "1200/1200 [==============================] - 1s 529us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 96/100\n",
      "1200/1200 [==============================] - 1s 502us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 97/100\n",
      "1200/1200 [==============================] - 1s 501us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 98/100\n",
      "1200/1200 [==============================] - 1s 503us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 99/100\n",
      "1200/1200 [==============================] - 1s 505us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "Epoch 100/100\n",
      "1200/1200 [==============================] - 1s 505us/step - loss: 1.0000 - accuracy: 0.6980\n",
      "300/300 [==============================] - 0s 347us/step - loss: 1.0000 - accuracy: 0.6894\n",
      "[1.0, 0.6893820762634277]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.69      1.00      0.82      6616\n",
      "         1.0       0.00      0.00      0.00      2815\n",
      "         2.0       0.00      0.00      0.00       166\n",
      "\n",
      "    accuracy                           0.69      9597\n",
      "   macro avg       0.23      0.33      0.27      9597\n",
      "weighted avg       0.48      0.69      0.56      9597\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmioi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\mmioi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\mmioi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANN1(x_train, Y_train, x_test, Y_test,\"squared_hinge\", -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38c04e5",
   "metadata": {},
   "source": [
    "# Balancing the Subsetted Data Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "b9b0e3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random under-sampling:\n",
      "0.0    13709\n",
      "1.0    13709\n",
      "2.0      866\n",
      "Name: parent_incident_type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "count_class_0, count_class_1 ,count_class_2= subsets.parent_incident_type.value_counts()\n",
    "df_class_0 = subsets[subsets['parent_incident_type'] == 0]\n",
    "df_class_1 = subsets[subsets['parent_incident_type'] == 1]\n",
    "df_class_2 = subsets[subsets['parent_incident_type'] == 2]\n",
    "# Undersample 0-class and concat the DataFrames of both class\n",
    "df_class_0_under = df_class_0.sample(count_class_1)\n",
    "df_test_under = pd.concat([df_class_0_under, df_class_1,df_class_2], axis=0)\n",
    "\n",
    "print('Random under-sampling:')\n",
    "print(df_test_under.parent_incident_type.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "bd324016",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_test_under.drop('parent_incident_type',axis=1).values\n",
    "Y=df_test_under.parent_incident_type.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "d3aa72ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "708/708 [==============================] - 0s 503us/step - loss: 22.1158 - accuracy: 0.4843\n",
      "Epoch 2/100\n",
      "708/708 [==============================] - 0s 502us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 3/100\n",
      "708/708 [==============================] - 0s 503us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 4/100\n",
      "708/708 [==============================] - 0s 500us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 5/100\n",
      "708/708 [==============================] - 0s 499us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 6/100\n",
      "708/708 [==============================] - 0s 503us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 7/100\n",
      "708/708 [==============================] - 0s 503us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 8/100\n",
      "708/708 [==============================] - 0s 505us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 9/100\n",
      "708/708 [==============================] - 0s 500us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 10/100\n",
      "708/708 [==============================] - 0s 500us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 11/100\n",
      "708/708 [==============================] - 0s 502us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 12/100\n",
      "708/708 [==============================] - 0s 500us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 13/100\n",
      "708/708 [==============================] - 0s 500us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 14/100\n",
      "708/708 [==============================] - 0s 500us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 15/100\n",
      "708/708 [==============================] - 0s 502us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 16/100\n",
      "708/708 [==============================] - 0s 508us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 17/100\n",
      "708/708 [==============================] - 0s 500us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 18/100\n",
      "708/708 [==============================] - 0s 503us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 19/100\n",
      "708/708 [==============================] - 0s 498us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 20/100\n",
      "708/708 [==============================] - 0s 503us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 21/100\n",
      "708/708 [==============================] - 0s 509us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 22/100\n",
      "708/708 [==============================] - 0s 499us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 23/100\n",
      "708/708 [==============================] - 0s 502us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 24/100\n",
      "708/708 [==============================] - 0s 506us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 25/100\n",
      "708/708 [==============================] - 0s 503us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 26/100\n",
      "708/708 [==============================] - 0s 503us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 27/100\n",
      "708/708 [==============================] - 0s 530us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 28/100\n",
      "708/708 [==============================] - 0s 529us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 29/100\n",
      "708/708 [==============================] - 0s 508us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 30/100\n",
      "708/708 [==============================] - 0s 508us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 31/100\n",
      "708/708 [==============================] - 0s 500us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 32/100\n",
      "708/708 [==============================] - 0s 503us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 33/100\n",
      "708/708 [==============================] - 0s 506us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 34/100\n",
      "708/708 [==============================] - 0s 499us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 35/100\n",
      "708/708 [==============================] - 0s 503us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 36/100\n",
      "708/708 [==============================] - 0s 499us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 37/100\n",
      "708/708 [==============================] - 0s 502us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 38/100\n",
      "708/708 [==============================] - 0s 503us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 39/100\n",
      "708/708 [==============================] - 0s 499us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 40/100\n",
      "708/708 [==============================] - 0s 506us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 41/100\n",
      "708/708 [==============================] - 0s 520us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 42/100\n",
      "708/708 [==============================] - 0s 503us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 43/100\n",
      "708/708 [==============================] - 0s 508us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 44/100\n",
      "708/708 [==============================] - 0s 499us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 45/100\n",
      "708/708 [==============================] - 0s 499us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 46/100\n",
      "708/708 [==============================] - 0s 510us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 47/100\n",
      "708/708 [==============================] - 0s 500us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 48/100\n",
      "708/708 [==============================] - 0s 502us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 49/100\n",
      "708/708 [==============================] - 0s 508us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 50/100\n",
      "708/708 [==============================] - 0s 503us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 51/100\n",
      "708/708 [==============================] - 0s 506us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 52/100\n",
      "708/708 [==============================] - 0s 509us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 53/100\n",
      "708/708 [==============================] - 0s 503us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 54/100\n",
      "708/708 [==============================] - 0s 505us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 55/100\n",
      "708/708 [==============================] - 0s 517us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 56/100\n",
      "708/708 [==============================] - 0s 512us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 57/100\n",
      "708/708 [==============================] - 0s 509us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 58/100\n",
      "708/708 [==============================] - 0s 510us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 59/100\n",
      "708/708 [==============================] - 0s 506us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 60/100\n",
      "708/708 [==============================] - 0s 509us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 61/100\n",
      "708/708 [==============================] - 0s 509us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 62/100\n",
      "708/708 [==============================] - 0s 500us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 63/100\n",
      "708/708 [==============================] - 0s 508us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 64/100\n",
      "708/708 [==============================] - 0s 505us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 65/100\n",
      "708/708 [==============================] - 0s 503us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 66/100\n",
      "708/708 [==============================] - 0s 513us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 67/100\n",
      "708/708 [==============================] - 0s 502us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 68/100\n",
      "708/708 [==============================] - 0s 502us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 69/100\n",
      "708/708 [==============================] - 0s 506us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 70/100\n",
      "708/708 [==============================] - 0s 502us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 71/100\n",
      "708/708 [==============================] - 0s 517us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 72/100\n",
      "708/708 [==============================] - 0s 526us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 73/100\n",
      "708/708 [==============================] - 0s 515us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 74/100\n",
      "708/708 [==============================] - 0s 513us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 75/100\n",
      "708/708 [==============================] - 0s 510us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 76/100\n",
      "708/708 [==============================] - 0s 503us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 77/100\n",
      "708/708 [==============================] - 0s 505us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 78/100\n",
      "708/708 [==============================] - 0s 512us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "708/708 [==============================] - 0s 522us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 80/100\n",
      "708/708 [==============================] - 0s 505us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 81/100\n",
      "708/708 [==============================] - 0s 510us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 82/100\n",
      "708/708 [==============================] - 0s 516us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 83/100\n",
      "708/708 [==============================] - 0s 508us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 84/100\n",
      "708/708 [==============================] - 0s 515us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 85/100\n",
      "708/708 [==============================] - 0s 506us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 86/100\n",
      "708/708 [==============================] - 0s 522us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 87/100\n",
      "708/708 [==============================] - 0s 509us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 88/100\n",
      "708/708 [==============================] - 0s 510us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 89/100\n",
      "708/708 [==============================] - 0s 510us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 90/100\n",
      "708/708 [==============================] - 0s 516us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 91/100\n",
      "708/708 [==============================] - 0s 516us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 92/100\n",
      "708/708 [==============================] - 0s 512us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 93/100\n",
      "708/708 [==============================] - 0s 512us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 94/100\n",
      "708/708 [==============================] - 0s 506us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 95/100\n",
      "708/708 [==============================] - 0s 505us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 96/100\n",
      "708/708 [==============================] - 0s 505us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 97/100\n",
      "708/708 [==============================] - 0s 500us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 98/100\n",
      "708/708 [==============================] - 0s 509us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 99/100\n",
      "708/708 [==============================] - 0s 508us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "Epoch 100/100\n",
      "708/708 [==============================] - 0s 509us/step - loss: 1.0000 - accuracy: 0.4863\n",
      "177/177 [==============================] - 0s 345us/step - loss: 1.0000 - accuracy: 0.4783\n",
      "[1.0, 0.47834542393684387]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      1.00      0.65      2706\n",
      "         1.0       0.00      0.00      0.00      2774\n",
      "         2.0       0.00      0.00      0.00       177\n",
      "\n",
      "    accuracy                           0.48      5657\n",
      "   macro avg       0.16      0.33      0.22      5657\n",
      "weighted avg       0.23      0.48      0.31      5657\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmioi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\mmioi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\mmioi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANN1(X_train, y_train, X_test, y_test,\"squared_hinge\", -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "0dfb16c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.05\n",
      "Accuracy score (training): 0.642\n",
      "Accuracy score (validation): 0.643\n",
      "\n",
      "Learning rate:  0.1\n",
      "Accuracy score (training): 0.650\n",
      "Accuracy score (validation): 0.650\n",
      "\n",
      "Learning rate:  0.25\n",
      "Accuracy score (training): 0.660\n",
      "Accuracy score (validation): 0.653\n",
      "\n",
      "Learning rate:  0.5\n",
      "Accuracy score (training): 0.670\n",
      "Accuracy score (validation): 0.655\n",
      "\n",
      "Learning rate:  0.75\n",
      "Accuracy score (training): 0.673\n",
      "Accuracy score (validation): 0.654\n",
      "\n",
      "Learning rate:  1\n",
      "Accuracy score (training): 0.679\n",
      "Accuracy score (validation): 0.641\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [0.05, 0.1, 0.25, 0.5, 0.75, 1]\n",
    "for learning_rate in learning_rates:\n",
    "    gb = GradientBoostingClassifier(n_estimators=200, learning_rate = learning_rate, max_features=5, max_depth = 2, random_state =2)\n",
    "    gb.fit(X_train, y_train)\n",
    "    print(\"Learning rate: \", learning_rate)\n",
    "    print(\"Accuracy score (training): {0:.3f}\".format(gb.score(X_train, y_train)))\n",
    "    print(\"Accuracy score (validation): {0:.3f}\".format(gb.score(X_test, y_test)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "91de085d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier as xg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "aadd63d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmioi\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:11:50] WARNING: D:\\bld\\xgboost-split_1631904903843\\work\\src\\learner.cc:573: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[10:11:50] WARNING: D:\\bld\\xgboost-split_1631904903843\\work\\src\\learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Learning rate:  0.05\n",
      "Accuracy score (training): 0.651\n",
      "Accuracy score (validation): 0.653\n",
      "\n",
      "[10:11:52] WARNING: D:\\bld\\xgboost-split_1631904903843\\work\\src\\learner.cc:573: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[10:11:52] WARNING: D:\\bld\\xgboost-split_1631904903843\\work\\src\\learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmioi\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.1\n",
      "Accuracy score (training): 0.657\n",
      "Accuracy score (validation): 0.657\n",
      "\n",
      "[10:11:53] WARNING: D:\\bld\\xgboost-split_1631904903843\\work\\src\\learner.cc:573: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[10:11:53] WARNING: D:\\bld\\xgboost-split_1631904903843\\work\\src\\learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmioi\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.25\n",
      "Accuracy score (training): 0.671\n",
      "Accuracy score (validation): 0.657\n",
      "\n",
      "[10:11:55] WARNING: D:\\bld\\xgboost-split_1631904903843\\work\\src\\learner.cc:573: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[10:11:55] WARNING: D:\\bld\\xgboost-split_1631904903843\\work\\src\\learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmioi\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.5\n",
      "Accuracy score (training): 0.685\n",
      "Accuracy score (validation): 0.660\n",
      "\n",
      "[10:11:56] WARNING: D:\\bld\\xgboost-split_1631904903843\\work\\src\\learner.cc:573: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[10:11:56] WARNING: D:\\bld\\xgboost-split_1631904903843\\work\\src\\learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmioi\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.75\n",
      "Accuracy score (training): 0.692\n",
      "Accuracy score (validation): 0.657\n",
      "\n",
      "[10:11:57] WARNING: D:\\bld\\xgboost-split_1631904903843\\work\\src\\learner.cc:573: \n",
      "Parameters: { \"max_features\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[10:11:57] WARNING: D:\\bld\\xgboost-split_1631904903843\\work\\src\\learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmioi\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  1\n",
      "Accuracy score (training): 0.699\n",
      "Accuracy score (validation): 0.653\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [0.05, 0.1, 0.25, 0.5, 0.75, 1]\n",
    "for learning_rate in learning_rates:\n",
    "    gb = xg(n_estimators=200, learning_rate = learning_rate, max_features=5, max_depth = 2, random_state =2)\n",
    "    gb.fit(X_train, y_train)\n",
    "    print(\"Learning rate: \", learning_rate)\n",
    "    print(\"Accuracy score (training): {0:.3f}\".format(gb.score(X_train, y_train)))\n",
    "    print(\"Accuracy score (validation): {0:.3f}\".format(gb.score(X_test, y_test)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "9109b5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmioi\\anaconda3\\lib\\site-packages\\xgboost\\core.py:430: FutureWarning: Pass `objective` as keyword args.  Passing these as positional arguments will be considered as error in future releases.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:53:13] WARNING: D:\\bld\\xgboost-split_1631904903843\\work\\src\\learner.cc:573: \n",
      "Parameters: { \"eval\", \"max_features\", \"num_round\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[10:53:13] WARNING: D:\\bld\\xgboost-split_1631904903843\\work\\src\\learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Learning rate:  0.05\n",
      "Accuracy score (training): 0.715\n",
      "Accuracy score (validation): 0.665\n",
      "\n",
      "[10:53:17] WARNING: D:\\bld\\xgboost-split_1631904903843\\work\\src\\learner.cc:573: \n",
      "Parameters: { \"eval\", \"max_features\", \"num_round\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[10:53:17] WARNING: D:\\bld\\xgboost-split_1631904903843\\work\\src\\learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmioi\\anaconda3\\lib\\site-packages\\xgboost\\core.py:430: FutureWarning: Pass `objective` as keyword args.  Passing these as positional arguments will be considered as error in future releases.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.1\n",
      "Accuracy score (training): 0.755\n",
      "Accuracy score (validation): 0.661\n",
      "\n",
      "[10:53:20] WARNING: D:\\bld\\xgboost-split_1631904903843\\work\\src\\learner.cc:573: \n",
      "Parameters: { \"eval\", \"max_features\", \"num_round\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[10:53:20] WARNING: D:\\bld\\xgboost-split_1631904903843\\work\\src\\learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmioi\\anaconda3\\lib\\site-packages\\xgboost\\core.py:430: FutureWarning: Pass `objective` as keyword args.  Passing these as positional arguments will be considered as error in future releases.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.25\n",
      "Accuracy score (training): 0.852\n",
      "Accuracy score (validation): 0.648\n",
      "\n",
      "[10:53:24] WARNING: D:\\bld\\xgboost-split_1631904903843\\work\\src\\learner.cc:573: \n",
      "Parameters: { \"eval\", \"max_features\", \"num_round\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[10:53:24] WARNING: D:\\bld\\xgboost-split_1631904903843\\work\\src\\learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmioi\\anaconda3\\lib\\site-packages\\xgboost\\core.py:430: FutureWarning: Pass `objective` as keyword args.  Passing these as positional arguments will be considered as error in future releases.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.5\n",
      "Accuracy score (training): 0.935\n",
      "Accuracy score (validation): 0.635\n",
      "\n",
      "[10:53:28] WARNING: D:\\bld\\xgboost-split_1631904903843\\work\\src\\learner.cc:573: \n",
      "Parameters: { \"eval\", \"max_features\", \"num_round\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[10:53:28] WARNING: D:\\bld\\xgboost-split_1631904903843\\work\\src\\learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmioi\\anaconda3\\lib\\site-packages\\xgboost\\core.py:430: FutureWarning: Pass `objective` as keyword args.  Passing these as positional arguments will be considered as error in future releases.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.75\n",
      "Accuracy score (training): 0.973\n",
      "Accuracy score (validation): 0.628\n",
      "\n",
      "[10:53:32] WARNING: D:\\bld\\xgboost-split_1631904903843\\work\\src\\learner.cc:573: \n",
      "Parameters: { \"eval\", \"max_features\", \"num_round\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[10:53:32] WARNING: D:\\bld\\xgboost-split_1631904903843\\work\\src\\learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmioi\\anaconda3\\lib\\site-packages\\xgboost\\core.py:430: FutureWarning: Pass `objective` as keyword args.  Passing these as positional arguments will be considered as error in future releases.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  1\n",
      "Accuracy score (training): 0.988\n",
      "Accuracy score (validation): 0.616\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param = {'max_depth': 2, 'eta': 1, 'objective': 'binary:logistic'}\n",
    "num_round = 2\n",
    "learning_rates = [0.05, 0.1, 0.25, 0.5, 0.75, 1]\n",
    "for learning_rate in learning_rates:\n",
    "    gb = xg(param,num_round=num_round, n_estimators=200, learning_rate = learning_rate, max_features=5, random_state =2,eval='auc', use_label_encoder=False)\n",
    "    gb.fit(X_train, y_train)\n",
    "    print(\"Learning rate: \", learning_rate)\n",
    "    print(\"Accuracy score (training): {0:.3f}\".format(gb.score(X_train, y_train)))\n",
    "    print(\"Accuracy score (validation): {0:.3f}\".format(gb.score(X_test, y_test)))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "765a11ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mmioi\\anaconda3\\lib\\site-packages\\xgboost\\core.py:430: FutureWarning: Pass `objective` as keyword args.  Passing these as positional arguments will be considered as error in future releases.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:54:00] WARNING: D:\\bld\\xgboost-split_1631904903843\\work\\src\\learner.cc:573: \n",
      "Parameters: { \"max_features\", \"num_round\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.85      0.80      6616\n",
      "         1.0       0.51      0.38      0.43      2815\n",
      "         2.0       0.20      0.02      0.04       166\n",
      "\n",
      "    accuracy                           0.70      9597\n",
      "   macro avg       0.48      0.42      0.42      9597\n",
      "weighted avg       0.67      0.70      0.68      9597\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gb = xg(param,num_round=num_round, n_estimators=200, learning_rate = 1, max_features=5, random_state =2,eval_metric='auc', use_label_encoder=False)\n",
    "gb.fit(x_train, Y_train)\n",
    "ypred=gb.predict(x_test)\n",
    "print(classification_report(Y_test,ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d73df90",
   "metadata": {},
   "source": [
    "# XGB Looks like our selected algo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19352b51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
